{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbb107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import copy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IOHMM import UnSupervisedIOHMM\n",
    "from IOHMM import OLS, DiscreteMNL, CrossEntropyMNL\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c58f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4f6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from sklearn.model_selection import train_test_split\n",
    "def assign_task(n):\n",
    "    sequence = np.random.random(n)\n",
    "    sequence[sequence>0.5] = 1\n",
    "    sequence[sequence<=0.5] = 0\n",
    "    return sequence\n",
    "    \n",
    "def covxy(x,y):\n",
    "    if type(x) == list:\n",
    "        x = np.array(x)\n",
    "    if type(y) == list:\n",
    "        y = np.array(y)\n",
    "    covxy = np.mean((x - x.mean()) * (y - y.mean()))\n",
    "    return covxy\n",
    "\n",
    "\n",
    "N =1000\n",
    "# analyze human reliance prob\n",
    "query = pd.read_csv(\"query_.csv\")\n",
    "data = pd.read_csv(\"predictions_0110.csv\")\n",
    "data[\"taskId\"] = data[\"taskId\"].apply(lambda x:int(x))\n",
    "data = data[data[\"taskId\"]<16]\n",
    "data[\"human_confidence\"] = data[\"imageName\"].apply(lambda x:query.query(\"Name==@x\")[\"Confidence_Pred_val\"].item())\n",
    "data[\"human_confidence\"] = data[\"human_confidence\"].apply(lambda x:1 if x>0.5 else 0)\n",
    "selected_data = data[data[\"attackType\"]==0]\n",
    "workers = list(set(selected_data[\"workerId\"]))\n",
    "h_a = []\n",
    "h_n = []\n",
    "l_a = []\n",
    "l_n = []\n",
    "for w in workers:\n",
    "    d = data.query(\"workerId==@w\")\n",
    "    h_num = len(d.query(\"human_confidence==1\")[\"reliance\"])\n",
    "    l_num = len(d.query(\"human_confidence==0\")[\"reliance\"])\n",
    "    h_a.append(d.query(\"human_confidence==1 and attack==0\")[\"reliance\"].sum()/h_num)\n",
    "    h_n.append(d.query(\"human_confidence==1 and attack==-1\")[\"reliance\"].sum()/h_num)\n",
    "    l_a.append(d.query(\"human_confidence==0 and attack==0\")[\"reliance\"].sum()/l_num)\n",
    "    l_n.append(d.query(\"human_confidence==0 and attack==-1\")[\"reliance\"].sum()/l_num)\n",
    "mean = torch.tensor([np.mean(l_a),np.mean(h_a),np.mean(l_n),np.mean(h_n)])\n",
    "var = torch.tensor([[covxy(l_a,l_a),covxy(l_a,h_a),covxy(l_a,l_n),covxy(l_a,h_n)],[covxy(h_a,l_a),covxy(h_a,h_a),covxy(h_a,l_n),covxy(h_a,h_n)],\n",
    "                   [covxy(l_n,l_a),covxy(l_n,h_a),covxy(l_n,l_n),covxy(l_n,h_n)],[covxy(h_n,l_a),covxy(h_n,h_a),covxy(h_n,l_n),covxy(h_n,h_n)]])\n",
    "\n",
    "dis = MultivariateNormal(mean, var)\n",
    "prob = dis.sample([N])\n",
    "humans = []\n",
    "for i in range(prob.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(prob.shape[1]):\n",
    "        if prob[i,j] >= 1 or prob[i,j]<=0:\n",
    "            flag = 0\n",
    "            break\n",
    "        else:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        humans.append(prob[i,:].numpy())\n",
    "\n",
    "task_pool = assign_task(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7c2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = MultivariateNormal(mean, var)\n",
    "prob = dis.sample([N])\n",
    "humans = []\n",
    "for i in range(prob.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(prob.shape[1]):\n",
    "        if prob[i,j] >= 1 or prob[i,j]<=0:\n",
    "            flag = 0\n",
    "            break\n",
    "        else:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        humans.append(prob[i,:].numpy())\n",
    "train_human, test_human, _, _ = train_test_split(humans,[0 for i in range(len(humans))], test_size=0.1, random_state=2023)\n",
    "test_humans = [np.concatenate((i,i),0) for i in test_human]\n",
    "# baselines [low_attack, high_attack, low_no, high_No]\n",
    "W_a = [-1,-0.5,0]\n",
    "W_r = [0.25,0.75,1]\n",
    "C = np.linspace(0,1,11)\n",
    "# no attack\n",
    "def no_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "\n",
    "    return w_a * accept + w_r * reject - attack * c\n",
    "\n",
    "\n",
    "def all_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = n\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "\n",
    "    return w_a * accept + w_r * reject - n*len(humans) * c\n",
    "\n",
    "def half_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "   \n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        p = np.random.choice([i for i in range(n)],n//2, replace =None)\n",
    "        attack_p = np.zeros(n)\n",
    "        attack_p[p] = 1\n",
    "        for k, t in enumerate(tasks):\n",
    "            if t == 0 and attack_p[k]==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            elif t == 1 and attack_p[k]==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            elif t == 0 and attack_p[k] == 1:\n",
    "                attack+= 1\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                attack+=1\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])  \n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "    return w_a * accept + w_r * reject - attack*c\n",
    "\n",
    "def high_confidence_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])\n",
    "                attack += 1\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "    return w_a * accept + w_r * reject - attack * c\n",
    "\n",
    "\n",
    "def eval_func(func, n, w_a, w_r, c, humans, num=50):\n",
    "    u = []\n",
    "    for _ in range(num):\n",
    "        u.append(func(n, w_a,w_r,c,humans))\n",
    "    return sum(u)/num\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0826756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def trust_transition(model, inputs, state_src, state_dst):\n",
    "#     inputs = add_constant(inputs,has_constant='add')\n",
    "    prob = np.exp(model.model_transition[state_src].predict_log_proba(inputs)).reshape(model.num_states)\n",
    "    return prob[state_dst]\n",
    "\n",
    "def reliance_prob(model, inputs, state):\n",
    "#     inputs = add_constant(inputs,has_constant='add')\n",
    "\n",
    "    return np.exp(model.model_emissions[state][0].predict_log_proba(inputs)).reshape(2)\n",
    "\n",
    "\n",
    "def reward(model, state, confidence,attack, w_a, w_r, c):\n",
    "    inputs = np.array([[confidence, attack]])\n",
    "\n",
    "    r = 0\n",
    "    for i in range(model.num_states):\n",
    "\n",
    "        r += trust_transition(model, inputs, state, i)* (reliance_prob(model, inputs,i)[0]*w_r +\n",
    "                                                         reliance_prob(model, inputs,i)[1]*w_a - attack*c)\n",
    "    return r\n",
    "        \n",
    "def reward_belief(model, belief, confidence,attack, w_a, w_r, c):\n",
    "    r = 0\n",
    "    for i in range(belief.shape[0]):\n",
    "        r += belief[i] * reward(model, i, confidence, attack, w_a, w_r, c)\n",
    "    return r\n",
    "\n",
    "def EU_max(model, belief, confidence, attack, l, w_a, w_r, c,max_length=2):\n",
    "    if l < 1:\n",
    "        print(\"error: l should be greated than 1\")\n",
    "    if l == 1:\n",
    "        eu_max = reward_belief(model, belief, confidence, attack, w_a, w_r, c)\n",
    "        return eu_max\n",
    "    else:\n",
    "        r = reward_belief(model, belief, confidence, attack, w_a, w_r, c)\n",
    "        eu_max = r \n",
    "        for d in [0,1]:\n",
    "            sum_ = 0\n",
    "            updated_b = update_belief(model, belief, confidence, attack,reliance=d)\n",
    "            for k in range(belief.shape[0]):\n",
    "                b_k = belief[k]\n",
    "                inputs = np.array([[ confidence, attack]])\n",
    "                for i in range(model.num_states):\n",
    "                    \n",
    "                    sum_ += b_k*trust_transition(model, inputs, k, i)*(reliance_prob(model,inputs,i)[d]*max(0.5*(EU_max(model, updated_b,confidence=0,attack=0,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)\n",
    "                                                                                                              +EU_max(model, updated_b,confidence=1,attack=0,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)),\n",
    "                                                                                    0.5*(EU_max(model, updated_b,confidence=0,attack=1,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)+EU_max(model, updated_b,confidence=1,attack=1,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c))))\n",
    "            eu_max += sum_\n",
    "        return eu_max\n",
    "\n",
    "def update_belief(model,belief, confidence, attack, reliance, constant = 1):\n",
    "    updated_b = np.zeros_like(belief)\n",
    "    inputs = np.array([[confidence, attack]])\n",
    "    for j in range(belief.shape[0]):\n",
    "        for i in range(belief.shape[0]):\n",
    "            updated_b[j] += constant*belief[i]*trust_transition(model, inputs, state_src=i,state_dst=j)*reliance_prob(model, inputs, j)[reliance]\n",
    "    return updated_b\n",
    "    \n",
    "def covxy(x,y):\n",
    "    if type(x) == list:\n",
    "        x = np.array(x)\n",
    "    if type(y) == list:\n",
    "        y = np.array(y)\n",
    "    covxy = np.mean((x - x.mean()) * (y - y.mean()))\n",
    "    return covxy\n",
    "\n",
    "def hmm_attack_helper(model, n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        b = np.array([1/model.num_states for i in range(model.num_states)])\n",
    "\n",
    "        tasks = assign_task(n)\n",
    "        for k, t in enumerate(tasks):\n",
    "            \n",
    "            action = np.argmax([EU_max(model, b, t, 0, n-k, w_a, w_r, c),EU_max(model, b, t, 1, n-k, w_a, w_r, c)])\n",
    "            \n",
    "            if t == 0 and action==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            elif t == 1 and action==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            elif t == 0 and action == 1:\n",
    "                attack+= 1\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                attack+=1\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]]) \n",
    "            b = update_belief(model, b, t,action, d)\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "            print(accept, reject, attack)\n",
    "    return w_a * accept + w_r * reject - attack*c\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval hmm-based algorithm\n",
    "\n",
    "#1. contruct human behavior data\n",
    "hmm_data = selected_data\n",
    "behavior_data = []\n",
    "hmm_data[\"reliance\"] = hmm_data[\"reliance\"].apply(lambda x: 1 if x == True else -1)\n",
    "hmm_data[\"attack\"] = hmm_data[\"attack\"].apply(lambda x:1 if x == 0 else x)\n",
    "hmm_data[\"human_confidence\"] = hmm_data[\"human_confidence\"].apply(lambda x:-1 if x == 0 else x)\n",
    "workers = list(set(selected_data[\"workerId\"]))\n",
    "for w in workers:\n",
    "    d = hmm_data.query(\"workerId==@w\").sort_values(by=[\"taskId\"])\n",
    "    behavior_data.append(d[[\"human_confidence\",\"attack\", \"reliance\"]])\n",
    "initial_columns = [\"human_confidence\", \"attack\"]\n",
    "transition_columns = [\"human_confidence\", \"attack\"]\n",
    "decision_columns = [\"human_confidence\", \"attack\"]\n",
    "\n",
    "model = UnSupervisedIOHMM(num_states=2, max_EM_iter=200, EM_tol=1e-6)\n",
    "\n",
    "model.set_models(model_emissions = [DiscreteMNL(solver='lbfgs')], \n",
    "                model_transition=CrossEntropyMNL(solver='lbfgs'),\n",
    "                model_initial=CrossEntropyMNL(solver='lbfgs'))\n",
    "\n",
    "model.set_inputs(covariates_initial = initial_columns, covariates_transition = initial_columns, covariates_emissions = [initial_columns])\n",
    "\n",
    "model.set_outputs([['reliance']])\n",
    "\n",
    "model.set_data(behavior_data)\n",
    "model.train()\n",
    "# hmm_attack_helper(model, 20,0,0.5,0.15, test_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b0e1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack cost:---->0.1\n",
      "high confidence:233.34999999999997\n",
      "half attack:251.58\n",
      "all attack:292.18\n",
      "no attack:210.84\n",
      "attack cost:---->0.11\n",
      "high confidence:227.87999999999997\n",
      "half attack:247.7700000000002\n",
      "all attack:280.7500000000002\n",
      "no attack:212.66\n",
      "attack cost:---->0.12\n",
      "high confidence:225.83479999999992\n",
      "half attack:242.75000000000014\n",
      "all attack:272.43999999999977\n",
      "no attack:210.09\n",
      "attack cost:---->0.13\n",
      "high confidence:219.0494000000001\n",
      "half attack:237.30999999999986\n",
      "all attack:262.80000000000024\n",
      "no attack:213.71\n",
      "attack cost:---->0.14\n",
      "high confidence:213.49839999999992\n",
      "half attack:232.40999999999977\n",
      "all attack:251.93999999999983\n",
      "no attack:213.22\n",
      "attack cost:---->0.15\n",
      "high confidence:209.10500000000008\n",
      "half attack:226.57\n",
      "all attack:242.66\n",
      "no attack:212.83\n",
      "attack cost:---->0.16\n",
      "high confidence:204.248\n",
      "half attack:221.15000000000018\n",
      "all attack:233.7600000000001\n",
      "no attack:213.03\n",
      "attack cost:---->0.17\n",
      "high confidence:198.60959999999994\n",
      "half attack:218.96000000000006\n",
      "all attack:225.0499999999998\n",
      "no attack:212.76\n",
      "attack cost:---->0.18\n",
      "high confidence:193.45479999999995\n",
      "half attack:212.14999999999992\n",
      "all attack:212.3500000000002\n",
      "no attack:211.1\n",
      "attack cost:---->0.19\n",
      "high confidence:187.47359999999998\n",
      "half attack:206.94999999999982\n",
      "all attack:205.29999999999993\n",
      "no attack:214.92\n"
     ]
    }
   ],
   "source": [
    "C = [i *0.01 for i in range(10,20)]\n",
    "for c in C:\n",
    "    print(\"attack cost:---->{}\".format(c))\n",
    "    print(\"high confidence:{}\".format(eval_func(high_confidence_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"half attack:{}\".format(eval_func(half_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"all attack:{}\".format(eval_func(all_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"no attack:{}\".format(eval_func(no_attack_helper, 20,0,0.5,c, test_humans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbd6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1\n",
      "0 2 2\n",
      "0 3 3\n",
      "0 4 4\n",
      "0 5 5\n",
      "0 6 6\n",
      "0 7 7\n",
      "0 8 8\n",
      "1 8 9\n",
      "1 9 10\n",
      "1 10 11\n",
      "1 11 12\n",
      "2 11 13\n",
      "2 12 14\n",
      "2 13 15\n",
      "2 14 16\n",
      "2 15 17\n",
      "2 16 18\n",
      "2 17 19\n",
      "3 17 20\n",
      "3 18 21\n",
      "3 19 22\n",
      "4 19 23\n",
      "4 20 24\n",
      "4 21 25\n",
      "4 22 26\n",
      "4 23 27\n",
      "5 23 28\n",
      "5 24 29\n",
      "5 25 30\n",
      "5 26 31\n",
      "5 27 32\n",
      "5 28 33\n",
      "5 29 34\n",
      "5 30 35\n",
      "6 30 36\n",
      "6 31 37\n",
      "6 32 38\n",
      "6 33 39\n",
      "6 34 40\n",
      "6 35 41\n",
      "7 35 42\n",
      "8 35 42\n",
      "9 35 42\n",
      "9 36 42\n",
      "9 37 42\n",
      "9 38 43\n",
      "9 39 44\n",
      "10 39 45\n",
      "10 40 46\n",
      "11 40 47\n",
      "11 41 48\n",
      "11 42 49\n",
      "11 43 50\n",
      "11 44 51\n",
      "12 44 52\n",
      "12 45 53\n",
      "12 46 54\n",
      "12 47 55\n",
      "12 48 56\n",
      "12 49 57\n",
      "12 50 58\n",
      "12 51 59\n",
      "12 52 60\n",
      "12 53 61\n",
      "12 54 62\n",
      "12 55 63\n",
      "13 55 64\n",
      "13 56 65\n",
      "14 56 66\n",
      "15 56 67\n",
      "15 57 67\n",
      "16 57 67\n",
      "16 58 68\n",
      "16 59 69\n",
      "16 60 70\n",
      "17 60 71\n",
      "17 61 72\n",
      "18 61 73\n",
      "18 62 74\n",
      "19 62 75\n",
      "19 63 75\n",
      "19 64 75\n",
      "19 65 76\n",
      "20 65 77\n",
      "21 65 78\n",
      "21 66 78\n",
      "22 66 79\n",
      "23 66 79\n",
      "23 67 79\n",
      "24 67 79\n",
      "24 68 80\n",
      "24 69 81\n",
      "24 70 82\n",
      "24 71 83\n",
      "24 72 84\n",
      "24 73 85\n",
      "25 73 86\n",
      "25 74 87\n",
      "25 75 88\n",
      "25 76 89\n",
      "25 77 90\n",
      "26 77 91\n",
      "26 78 92\n",
      "27 78 93\n",
      "27 79 94\n",
      "27 80 95\n",
      "27 81 96\n",
      "27 82 97\n",
      "28 82 98\n",
      "28 83 99\n",
      "28 84 100\n",
      "29 84 101\n",
      "29 85 102\n",
      "30 85 103\n",
      "30 86 104\n",
      "30 87 105\n",
      "30 88 106\n",
      "30 89 107\n",
      "30 90 108\n",
      "30 91 109\n",
      "31 91 110\n",
      "31 92 111\n",
      "31 93 112\n",
      "32 93 113\n",
      "32 94 114\n",
      "32 95 115\n",
      "32 96 116\n",
      "32 97 117\n",
      "32 98 118\n",
      "33 98 119\n",
      "33 99 120\n",
      "33 100 121\n",
      "33 101 122\n",
      "33 102 123\n",
      "33 103 124\n",
      "34 103 125\n",
      "34 104 126\n",
      "34 105 127\n",
      "34 106 128\n",
      "34 107 129\n",
      "34 108 130\n",
      "34 109 131\n",
      "34 110 132\n",
      "34 111 133\n",
      "34 112 134\n",
      "34 113 135\n",
      "34 114 136\n",
      "34 115 137\n",
      "34 116 138\n",
      "34 117 139\n",
      "34 118 140\n",
      "34 119 141\n",
      "35 119 142\n",
      "36 119 143\n",
      "36 120 144\n",
      "36 121 145\n",
      "36 122 146\n",
      "36 123 147\n",
      "36 124 148\n",
      "37 124 149\n",
      "37 125 149\n",
      "38 125 150\n",
      "38 126 150\n",
      "39 126 151\n",
      "39 127 151\n",
      "40 127 152\n",
      "41 127 152\n",
      "42 127 152\n",
      "42 128 152\n",
      "43 128 152\n",
      "44 128 152\n",
      "45 128 152\n",
      "46 128 152\n",
      "47 128 152\n",
      "48 128 152\n",
      "49 128 152\n",
      "50 128 152\n",
      "50 129 152\n",
      "51 129 152\n",
      "51 130 153\n",
      "52 130 154\n",
      "52 131 154\n",
      "53 131 155\n",
      "53 132 155\n",
      "54 132 156\n",
      "55 132 156\n",
      "56 132 156\n",
      "56 133 156\n",
      "57 133 156\n",
      "57 134 156\n",
      "57 135 157\n",
      "57 136 158\n",
      "58 136 159\n",
      "59 136 160\n",
      "59 137 160\n",
      "60 137 161\n",
      "61 137 161\n",
      "61 138 161\n",
      "62 138 162\n",
      "63 138 163\n",
      "64 138 163\n",
      "65 138 163\n",
      "66 138 163\n",
      "66 139 163\n",
      "66 140 163\n",
      "66 141 163\n",
      "66 142 164\n",
      "66 143 165\n",
      "66 144 166\n",
      "66 145 167\n",
      "66 146 168\n",
      "66 147 169\n",
      "66 148 170\n",
      "67 148 171\n",
      "67 149 172\n",
      "68 149 173\n",
      "68 150 173\n",
      "68 151 174\n",
      "68 152 175\n",
      "69 152 176\n",
      "70 152 176\n",
      "70 153 176\n",
      "70 154 176\n",
      "70 155 177\n",
      "70 156 178\n",
      "70 157 179\n",
      "70 158 180\n",
      "70 159 181\n",
      "71 159 182\n",
      "71 160 183\n",
      "71 161 184\n",
      "72 161 185\n",
      "72 162 186\n",
      "72 163 187\n",
      "73 163 188\n",
      "73 164 189\n",
      "73 165 190\n",
      "73 166 191\n",
      "73 167 192\n",
      "73 168 193\n",
      "73 169 194\n",
      "73 170 195\n",
      "73 171 196\n",
      "73 172 197\n",
      "74 172 198\n",
      "74 173 199\n",
      "74 174 200\n",
      "74 175 201\n",
      "74 176 202\n",
      "74 177 203\n",
      "75 177 204\n",
      "75 178 205\n",
      "75 179 206\n",
      "75 180 207\n",
      "76 180 208\n",
      "76 181 209\n",
      "76 182 210\n",
      "76 183 211\n",
      "76 184 212\n",
      "76 185 213\n",
      "76 186 214\n",
      "76 187 215\n",
      "76 188 216\n",
      "76 189 217\n",
      "77 189 218\n",
      "77 190 219\n",
      "77 191 220\n",
      "77 192 221\n",
      "77 193 222\n",
      "77 194 223\n",
      "77 195 224\n",
      "77 196 225\n",
      "78 196 226\n",
      "78 197 227\n",
      "78 198 228\n",
      "79 198 229\n",
      "79 199 230\n",
      "80 199 231\n",
      "80 200 232\n",
      "80 201 233\n",
      "80 202 234\n",
      "80 203 235\n",
      "80 204 236\n",
      "80 205 237\n",
      "80 206 238\n",
      "80 207 239\n",
      "81 207 240\n",
      "81 208 241\n",
      "81 209 242\n",
      "81 210 243\n",
      "82 210 244\n",
      "82 211 245\n",
      "83 211 246\n",
      "83 212 247\n",
      "84 212 248\n",
      "84 213 248\n",
      "85 213 249\n",
      "85 214 249\n",
      "85 215 250\n",
      "85 216 251\n",
      "85 217 252\n",
      "85 218 253\n",
      "86 218 254\n",
      "86 219 255\n",
      "86 220 256\n",
      "86 221 257\n",
      "86 222 258\n",
      "86 223 259\n",
      "86 224 260\n",
      "87 224 261\n",
      "87 225 262\n",
      "87 226 263\n",
      "87 227 264\n",
      "87 228 265\n",
      "88 228 266\n",
      "88 229 267\n",
      "88 230 268\n",
      "88 231 269\n",
      "88 232 270\n",
      "88 233 271\n",
      "88 234 272\n",
      "88 235 273\n",
      "88 236 274\n",
      "88 237 275\n",
      "88 238 276\n",
      "88 239 277\n",
      "88 240 278\n",
      "89 240 279\n",
      "89 241 280\n",
      "89 242 281\n",
      "90 242 282\n",
      "90 243 283\n",
      "90 244 284\n",
      "91 244 285\n",
      "91 245 286\n",
      "91 246 287\n",
      "91 247 288\n",
      "91 248 289\n",
      "92 248 290\n",
      "92 249 291\n",
      "93 249 292\n",
      "94 249 292\n",
      "95 249 292\n",
      "96 249 292\n",
      "97 249 292\n",
      "98 249 292\n",
      "98 250 292\n",
      "98 251 292\n",
      "99 251 293\n",
      "100 251 293\n",
      "101 251 293\n",
      "102 251 293\n",
      "103 251 293\n",
      "104 251 293\n",
      "105 251 293\n",
      "106 251 293\n",
      "107 251 293\n",
      "108 251 293\n",
      "108 252 293\n",
      "108 253 294\n",
      "108 254 295\n",
      "108 255 296\n",
      "108 256 297\n",
      "108 257 298\n",
      "108 258 299\n",
      "108 259 300\n",
      "108 260 301\n",
      "108 261 302\n",
      "109 261 303\n",
      "109 262 304\n",
      "109 263 305\n",
      "109 264 306\n",
      "109 265 307\n",
      "109 266 308\n",
      "109 267 309\n",
      "109 268 310\n",
      "109 269 311\n",
      "109 270 312\n",
      "109 271 313\n",
      "109 272 314\n",
      "110 272 315\n",
      "110 273 316\n",
      "110 274 317\n",
      "110 275 318\n",
      "110 276 319\n",
      "111 276 320\n",
      "111 277 321\n",
      "111 278 322\n",
      "111 279 323\n",
      "111 280 324\n",
      "111 281 325\n",
      "111 282 326\n",
      "111 283 327\n",
      "111 284 328\n",
      "111 285 329\n",
      "111 286 330\n",
      "111 287 331\n",
      "111 288 332\n",
      "111 289 333\n",
      "111 290 334\n",
      "111 291 335\n",
      "111 292 336\n",
      "111 293 337\n",
      "111 294 338\n",
      "111 295 339\n",
      "111 296 340\n",
      "112 296 341\n",
      "113 296 342\n",
      "114 296 342\n",
      "114 297 342\n",
      "114 298 343\n",
      "114 299 344\n",
      "114 300 345\n",
      "114 301 346\n",
      "114 302 347\n",
      "115 302 348\n",
      "115 303 349\n",
      "115 304 350\n",
      "115 305 351\n",
      "115 306 352\n",
      "115 307 353\n",
      "115 308 354\n",
      "115 309 355\n",
      "116 309 356\n",
      "116 310 357\n",
      "116 311 358\n",
      "116 312 359\n",
      "117 312 360\n",
      "117 313 361\n",
      "117 314 362\n",
      "117 315 363\n",
      "117 316 364\n",
      "117 317 365\n",
      "117 318 366\n",
      "117 319 367\n",
      "117 320 368\n",
      "117 321 369\n",
      "117 322 370\n",
      "117 323 371\n",
      "117 324 372\n",
      "117 325 373\n",
      "117 326 374\n",
      "117 327 375\n",
      "117 328 376\n",
      "117 329 377\n",
      "117 330 378\n",
      "117 331 379\n",
      "117 332 380\n",
      "117 333 381\n",
      "117 334 382\n",
      "117 335 383\n",
      "117 336 384\n",
      "117 337 385\n",
      "118 337 386\n",
      "118 338 387\n",
      "118 339 388\n",
      "118 340 389\n",
      "118 341 390\n",
      "118 342 391\n",
      "118 343 392\n",
      "118 344 393\n",
      "118 345 394\n",
      "118 346 395\n",
      "118 347 396\n",
      "118 348 397\n",
      "118 349 398\n",
      "118 350 399\n",
      "118 351 400\n",
      "118 352 401\n",
      "119 352 402\n",
      "119 353 403\n",
      "120 353 404\n",
      "120 354 404\n",
      "120 355 405\n",
      "120 356 406\n",
      "120 357 407\n",
      "120 358 408\n",
      "120 359 409\n",
      "120 360 410\n",
      "120 361 411\n",
      "120 362 412\n",
      "120 363 413\n",
      "120 364 414\n",
      "121 364 415\n",
      "121 365 416\n",
      "121 366 417\n",
      "121 367 418\n",
      "121 368 419\n",
      "121 369 420\n",
      "122 369 421\n",
      "122 370 422\n",
      "122 371 423\n",
      "122 372 424\n",
      "122 373 425\n",
      "122 374 426\n",
      "122 375 427\n",
      "123 375 428\n",
      "123 376 429\n",
      "123 377 430\n",
      "123 378 431\n",
      "123 379 432\n",
      "123 380 433\n",
      "123 381 434\n",
      "123 382 435\n",
      "123 383 436\n",
      "123 384 437\n",
      "124 384 438\n",
      "124 385 439\n",
      "124 386 440\n",
      "125 386 441\n",
      "125 387 442\n",
      "126 387 443\n",
      "127 387 443\n",
      "127 388 444\n",
      "127 389 445\n",
      "127 390 446\n",
      "127 391 447\n",
      "127 392 448\n",
      "127 393 449\n",
      "128 393 450\n",
      "128 394 450\n",
      "129 394 450\n",
      "129 395 450\n",
      "129 396 450\n",
      "129 397 451\n",
      "130 397 452\n",
      "131 397 453\n",
      "131 398 453\n",
      "131 399 454\n",
      "131 400 455\n",
      "132 400 456\n",
      "133 400 457\n",
      "133 401 457\n",
      "133 402 458\n",
      "134 402 459\n",
      "134 403 460\n",
      "134 404 461\n",
      "134 405 462\n",
      "134 406 463\n",
      "134 407 464\n",
      "134 408 465\n",
      "134 409 466\n",
      "134 410 467\n",
      "134 411 468\n",
      "134 412 469\n",
      "135 412 470\n",
      "136 412 471\n",
      "136 413 472\n",
      "137 413 473\n",
      "138 413 474\n",
      "138 414 474\n",
      "139 414 475\n",
      "140 414 475\n",
      "141 414 475\n",
      "141 415 475\n",
      "141 416 475\n",
      "141 417 476\n",
      "141 418 477\n",
      "142 418 478\n",
      "142 419 479\n",
      "142 420 480\n",
      "143 420 481\n",
      "143 421 482\n",
      "143 422 483\n",
      "143 423 484\n",
      "143 424 485\n",
      "143 425 486\n",
      "143 426 487\n",
      "143 427 488\n",
      "143 428 489\n",
      "143 429 490\n",
      "143 430 491\n",
      "143 431 492\n",
      "143 432 493\n",
      "143 433 494\n",
      "144 433 495\n",
      "144 434 496\n",
      "144 435 497\n",
      "144 436 498\n",
      "144 437 499\n",
      "144 438 500\n",
      "144 439 501\n",
      "145 439 502\n",
      "145 440 503\n",
      "145 441 504\n",
      "145 442 505\n",
      "145 443 506\n",
      "145 444 507\n",
      "145 445 508\n",
      "145 446 509\n",
      "145 447 510\n",
      "146 447 511\n",
      "147 447 512\n",
      "147 448 512\n",
      "147 449 513\n",
      "147 450 514\n",
      "147 451 515\n",
      "147 452 516\n",
      "147 453 517\n",
      "147 454 518\n",
      "147 455 519\n",
      "148 455 520\n",
      "148 456 521\n",
      "148 457 522\n",
      "148 458 523\n",
      "149 458 524\n",
      "149 459 525\n",
      "150 459 526\n",
      "150 460 527\n",
      "150 461 528\n",
      "150 462 529\n",
      "150 463 530\n",
      "150 464 531\n",
      "151 464 532\n",
      "151 465 533\n",
      "151 466 534\n",
      "151 467 535\n",
      "152 467 536\n",
      "153 467 537\n",
      "153 468 538\n",
      "153 469 539\n",
      "153 470 540\n",
      "153 471 541\n",
      "153 472 542\n",
      "154 472 543\n",
      "154 473 544\n",
      "155 473 545\n",
      "155 474 546\n",
      "156 474 547\n",
      "156 475 548\n",
      "157 475 549\n",
      "157 476 550\n",
      "157 477 551\n",
      "157 478 552\n",
      "157 479 553\n",
      "157 480 554\n",
      "157 481 555\n",
      "157 482 556\n",
      "157 483 557\n",
      "157 484 558\n",
      "157 485 559\n",
      "157 486 560\n",
      "157 487 561\n",
      "157 488 562\n",
      "157 489 563\n",
      "157 490 564\n",
      "157 491 565\n",
      "157 492 566\n",
      "157 493 567\n",
      "157 494 568\n",
      "157 495 569\n",
      "158 495 570\n",
      "158 496 571\n",
      "159 496 572\n",
      "160 496 572\n",
      "161 496 573\n",
      "162 496 573\n",
      "162 497 573\n",
      "163 497 573\n",
      "163 498 574\n",
      "163 499 575\n",
      "164 499 576\n",
      "164 500 577\n",
      "164 501 578\n",
      "164 502 579\n",
      "164 503 580\n",
      "164 504 581\n",
      "164 505 582\n",
      "164 506 583\n",
      "164 507 584\n",
      "164 508 585\n",
      "164 509 586\n",
      "164 510 587\n",
      "164 511 588\n",
      "164 512 589\n",
      "164 513 590\n",
      "164 514 591\n",
      "164 515 592\n",
      "164 516 593\n",
      "164 517 594\n",
      "165 517 595\n",
      "165 518 596\n",
      "165 519 597\n",
      "166 519 598\n",
      "167 519 599\n",
      "168 519 600\n",
      "169 519 600\n",
      "170 519 600\n",
      "171 519 600\n",
      "172 519 600\n",
      "173 519 600\n",
      "174 519 600\n",
      "174 520 600\n",
      "175 520 600\n",
      "176 520 600\n",
      "176 521 600\n",
      "176 522 600\n",
      "176 523 600\n",
      "176 524 601\n",
      "177 524 602\n",
      "178 524 602\n",
      "178 525 602\n",
      "178 526 602\n",
      "178 527 603\n",
      "178 528 604\n",
      "178 529 605\n",
      "178 530 606\n",
      "178 531 607\n",
      "178 532 608\n",
      "178 533 609\n",
      "178 534 610\n",
      "178 535 611\n",
      "178 536 612\n",
      "178 537 613\n",
      "178 538 614\n",
      "178 539 615\n",
      "178 540 616\n",
      "178 541 617\n",
      "178 542 618\n",
      "178 543 619\n",
      "179 543 620\n",
      "179 544 621\n",
      "180 544 622\n",
      "180 545 623\n",
      "181 545 624\n",
      "182 545 624\n",
      "183 545 624\n",
      "183 546 624\n",
      "183 547 625\n",
      "184 547 626\n",
      "184 548 627\n",
      "184 549 628\n",
      "184 550 629\n",
      "184 551 630\n",
      "184 552 631\n",
      "184 553 632\n",
      "184 554 633\n",
      "184 555 634\n",
      "184 556 635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 557 636\n",
      "184 558 637\n",
      "184 559 638\n",
      "184 560 639\n",
      "184 561 640\n",
      "184 562 641\n",
      "184 563 642\n",
      "184 564 643\n",
      "184 565 644\n",
      "184 566 645\n",
      "184 567 646\n",
      "184 568 647\n",
      "184 569 648\n",
      "184 570 649\n",
      "184 571 650\n",
      "184 572 651\n",
      "184 573 652\n",
      "184 574 653\n",
      "184 575 654\n",
      "184 576 655\n",
      "184 577 656\n",
      "184 578 657\n",
      "184 579 658\n",
      "184 580 659\n",
      "184 581 660\n",
      "184 582 661\n",
      "184 583 662\n",
      "184 584 663\n",
      "184 585 664\n",
      "184 586 665\n",
      "184 587 666\n",
      "184 588 667\n",
      "184 589 668\n",
      "184 590 669\n",
      "184 591 670\n",
      "184 592 671\n",
      "184 593 672\n",
      "184 594 673\n",
      "184 595 674\n",
      "185 595 675\n",
      "186 595 676\n",
      "186 596 676\n",
      "187 596 676\n",
      "188 596 676\n",
      "189 596 676\n",
      "189 597 676\n",
      "190 597 677\n",
      "190 598 677\n",
      "191 598 677\n",
      "192 598 677\n",
      "193 598 677\n",
      "194 598 677\n",
      "194 599 677\n",
      "194 600 677\n",
      "194 601 678\n",
      "194 602 679\n",
      "194 603 680\n",
      "194 604 681\n",
      "195 604 682\n",
      "195 605 683\n",
      "195 606 684\n",
      "195 607 685\n",
      "195 608 686\n",
      "196 608 687\n",
      "197 608 688\n",
      "197 609 689\n",
      "197 610 690\n",
      "197 611 691\n",
      "197 612 692\n",
      "197 613 693\n",
      "197 614 694\n",
      "198 614 695\n",
      "199 614 696\n",
      "200 614 696\n",
      "200 615 696\n",
      "201 615 696\n",
      "201 616 696\n",
      "202 616 697\n",
      "202 617 697\n",
      "202 618 698\n",
      "202 619 699\n",
      "202 620 700\n",
      "202 621 701\n",
      "202 622 702\n",
      "202 623 703\n",
      "202 624 704\n",
      "202 625 705\n",
      "202 626 706\n",
      "202 627 707\n",
      "203 627 708\n",
      "203 628 709\n",
      "203 629 710\n",
      "203 630 711\n",
      "203 631 712\n",
      "203 632 713\n",
      "203 633 714\n",
      "203 634 715\n",
      "203 635 716\n",
      "203 636 717\n",
      "204 636 718\n",
      "204 637 719\n",
      "204 638 720\n",
      "204 639 721\n",
      "204 640 722\n",
      "205 640 723\n",
      "205 641 724\n",
      "206 641 725\n",
      "207 641 725\n",
      "207 642 725\n",
      "207 643 726\n",
      "207 644 727\n",
      "207 645 728\n",
      "207 646 729\n",
      "207 647 730\n",
      "207 648 731\n",
      "207 649 732\n",
      "207 650 733\n",
      "207 651 734\n",
      "208 651 735\n",
      "208 652 736\n",
      "209 652 737\n",
      "210 652 737\n",
      "211 652 737\n",
      "212 652 737\n",
      "213 652 737\n",
      "214 652 737\n",
      "215 652 737\n",
      "216 652 737\n",
      "217 652 737\n",
      "218 652 737\n",
      "219 652 737\n",
      "220 652 737\n",
      "221 652 737\n",
      "222 652 737\n",
      "223 652 737\n",
      "224 652 737\n",
      "225 652 737\n",
      "226 652 737\n",
      "227 652 737\n",
      "228 652 737\n",
      "228 653 738\n",
      "229 653 739\n",
      "229 654 740\n",
      "229 655 741\n",
      "229 656 742\n",
      "229 657 743\n",
      "229 658 744\n",
      "229 659 745\n",
      "229 660 746\n",
      "229 661 747\n",
      "229 662 748\n",
      "229 663 749\n",
      "229 664 750\n",
      "229 665 751\n",
      "229 666 752\n",
      "229 667 753\n",
      "229 668 754\n",
      "229 669 755\n",
      "229 670 756\n",
      "229 671 757\n",
      "229 672 758\n",
      "229 673 759\n",
      "229 674 760\n",
      "229 675 761\n",
      "229 676 762\n",
      "230 676 763\n",
      "230 677 764\n",
      "230 678 765\n",
      "230 679 766\n",
      "231 679 767\n",
      "232 679 768\n",
      "232 680 768\n",
      "233 680 768\n",
      "233 681 768\n",
      "233 682 769\n",
      "233 683 770\n",
      "233 684 771\n",
      "233 685 772\n",
      "233 686 773\n",
      "233 687 774\n",
      "233 688 775\n",
      "234 688 776\n",
      "234 689 777\n",
      "234 690 778\n",
      "234 691 779\n",
      "235 691 780\n",
      "235 692 781\n",
      "236 692 782\n",
      "237 692 782\n",
      "238 692 782\n",
      "238 693 782\n",
      "238 694 782\n",
      "238 695 783\n",
      "238 696 784\n",
      "239 696 785\n",
      "239 697 786\n",
      "239 698 787\n",
      "239 699 788\n",
      "239 700 789\n",
      "239 701 790\n",
      "240 701 791\n",
      "240 702 791\n",
      "240 703 791\n",
      "240 704 792\n",
      "240 705 793\n",
      "240 706 794\n",
      "240 707 795\n",
      "240 708 796\n",
      "240 709 797\n",
      "240 710 798\n",
      "240 711 799\n",
      "240 712 800\n",
      "240 713 801\n",
      "240 714 802\n",
      "240 715 803\n",
      "240 716 804\n",
      "240 717 805\n",
      "240 718 806\n",
      "240 719 807\n",
      "240 720 808\n",
      "241 720 809\n",
      "242 720 809\n",
      "243 720 809\n",
      "243 721 809\n",
      "244 721 809\n",
      "245 721 809\n",
      "246 721 809\n",
      "247 721 809\n",
      "247 722 809\n",
      "247 723 809\n",
      "247 724 810\n",
      "248 724 811\n",
      "248 725 812\n",
      "248 726 813\n",
      "248 727 814\n",
      "249 727 815\n",
      "249 728 816\n",
      "249 729 817\n",
      "249 730 818\n",
      "250 730 819\n",
      "cost:0.1, utility:283.1\n",
      "0 1 1\n",
      "0 2 2\n",
      "0 3 3\n",
      "0 4 4\n",
      "0 5 5\n",
      "0 6 6\n",
      "1 6 7\n",
      "2 6 7\n",
      "2 7 7\n",
      "2 8 7\n",
      "2 9 8\n",
      "2 10 9\n",
      "3 10 9\n",
      "3 11 10\n",
      "3 12 11\n",
      "3 13 11\n",
      "3 14 12\n",
      "3 15 13\n",
      "3 16 13\n",
      "3 17 13\n",
      "3 18 14\n",
      "3 19 15\n",
      "3 20 16\n",
      "3 21 17\n",
      "3 22 18\n",
      "3 23 19\n",
      "3 24 20\n",
      "3 25 21\n",
      "3 26 22\n",
      "3 27 23\n",
      "3 28 24\n",
      "3 29 25\n"
     ]
    }
   ],
   "source": [
    "C = [i *0.01 for i in range(10,20)]\n",
    "for c in C:\n",
    "    print(\"cost:{}, utility:{}\".format(c, hmm_attack_helper(model, 20,0,0.5,c, test_humans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d3ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive",
   "language": "python",
   "name": "interactive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
