{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743b73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import copy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IOHMM import UnSupervisedIOHMM\n",
    "from IOHMM import OLS, DiscreteMNL, CrossEntropyMNL\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f74f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca73a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from sklearn.model_selection import train_test_split\n",
    "def assign_task(n):\n",
    "    sequence = np.random.random(n)\n",
    "    sequence[sequence>0.5] = 1\n",
    "    sequence[sequence<=0.5] = 0\n",
    "    return sequence\n",
    "    \n",
    "def covxy(x,y):\n",
    "    if type(x) == list:\n",
    "        x = np.array(x)\n",
    "    if type(y) == list:\n",
    "        y = np.array(y)\n",
    "    covxy = np.mean((x - x.mean()) * (y - y.mean()))\n",
    "    return covxy\n",
    "\n",
    "\n",
    "N =1000\n",
    "# analyze human reliance prob\n",
    "query = pd.read_csv(\"query_.csv\")\n",
    "data = pd.read_csv(\"predictions_0110.csv\")\n",
    "data[\"taskId\"] = data[\"taskId\"].apply(lambda x:int(x))\n",
    "data = data[data[\"taskId\"]<16]\n",
    "data[\"human_confidence\"] = data[\"imageName\"].apply(lambda x:query.query(\"Name==@x\")[\"Confidence_Pred_val\"].item())\n",
    "data[\"human_confidence\"] = data[\"human_confidence\"].apply(lambda x:1 if x>0.5 else 0)\n",
    "selected_data = data[data[\"attackType\"]==0]\n",
    "workers = list(set(selected_data[\"workerId\"]))\n",
    "h_a = []\n",
    "h_n = []\n",
    "l_a = []\n",
    "l_n = []\n",
    "for w in workers:\n",
    "    d = data.query(\"workerId==@w\")\n",
    "    h_num = len(d.query(\"human_confidence==1\")[\"reliance\"])\n",
    "    l_num = len(d.query(\"human_confidence==0\")[\"reliance\"])\n",
    "    h_a.append(d.query(\"human_confidence==1 and attack==0\")[\"reliance\"].sum()/h_num)\n",
    "    h_n.append(d.query(\"human_confidence==1 and attack==-1\")[\"reliance\"].sum()/h_num)\n",
    "    l_a.append(d.query(\"human_confidence==0 and attack==0\")[\"reliance\"].sum()/l_num)\n",
    "    l_n.append(d.query(\"human_confidence==0 and attack==-1\")[\"reliance\"].sum()/l_num)\n",
    "mean = torch.tensor([np.mean(l_a),np.mean(h_a),np.mean(l_n),np.mean(h_n)])\n",
    "var = torch.tensor([[covxy(l_a,l_a),covxy(l_a,h_a),covxy(l_a,l_n),covxy(l_a,h_n)],[covxy(h_a,l_a),covxy(h_a,h_a),covxy(h_a,l_n),covxy(h_a,h_n)],\n",
    "                   [covxy(l_n,l_a),covxy(l_n,h_a),covxy(l_n,l_n),covxy(l_n,h_n)],[covxy(h_n,l_a),covxy(h_n,h_a),covxy(h_n,l_n),covxy(h_n,h_n)]])\n",
    "\n",
    "dis = MultivariateNormal(mean, var)\n",
    "prob = dis.sample([N])\n",
    "humans = []\n",
    "for i in range(prob.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(prob.shape[1]):\n",
    "        if prob[i,j] >= 1 or prob[i,j]<=0:\n",
    "            flag = 0\n",
    "            break\n",
    "        else:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        humans.append(prob[i,:].numpy())\n",
    "\n",
    "task_pool = assign_task(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a889a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = MultivariateNormal(mean, var)\n",
    "prob = dis.sample([N])\n",
    "humans = []\n",
    "for i in range(prob.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(prob.shape[1]):\n",
    "        if prob[i,j] >= 1 or prob[i,j]<=0:\n",
    "            flag = 0\n",
    "            break\n",
    "        else:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        humans.append(prob[i,:].numpy())\n",
    "train_human, test_human, _, _ = train_test_split(humans,[0 for i in range(len(humans))], test_size=0.1, random_state=2023)\n",
    "test_humans = [np.concatenate((i,i),0) for i in test_human]\n",
    "# baselines [low_attack, high_attack, low_no, high_No]\n",
    "W_a = [-1,-0.5,0]\n",
    "W_r = [0.25,0.75,1]\n",
    "C = np.linspace(0,1,11)\n",
    "# no attack\n",
    "def no_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "\n",
    "    return w_a * accept + w_r * reject - attack * c\n",
    "\n",
    "\n",
    "def all_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = n\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "\n",
    "    return w_a * accept + w_r * reject - n*len(humans) * c\n",
    "\n",
    "def half_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "   \n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        p = np.random.choice([i for i in range(n)],n//2, replace =None)\n",
    "        attack_p = np.zeros(n)\n",
    "        attack_p[p] = 1\n",
    "        for k, t in enumerate(tasks):\n",
    "            if t == 0 and attack_p[k]==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            elif t == 1 and attack_p[k]==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            elif t == 0 and attack_p[k] == 1:\n",
    "                attack+= 1\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                attack+=1\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])  \n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "    return w_a * accept + w_r * reject - attack*c\n",
    "\n",
    "def high_confidence_attack_helper(n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        tasks = assign_task(n)\n",
    "        for t in tasks:\n",
    "            if t == 0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            else:\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]])\n",
    "                attack += 1\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "    return w_a * accept + w_r * reject - attack * c\n",
    "\n",
    "\n",
    "def eval_func(func, n, w_a, w_r, c, humans, num=50):\n",
    "    u = []\n",
    "    for _ in range(num):\n",
    "        u.append(func(n, w_a,w_r,c,humans))\n",
    "    return sum(u)/num\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0511f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def trust_transition(model, inputs, state_src, state_dst):\n",
    "#     inputs = add_constant(inputs,has_constant='add')\n",
    "    prob = np.exp(model.model_transition[state_src].predict_log_proba(inputs)).reshape(model.num_states)\n",
    "    return prob[state_dst]\n",
    "\n",
    "def reliance_prob(model, inputs, state):\n",
    "#     inputs = add_constant(inputs,has_constant='add')\n",
    "\n",
    "    return np.exp(model.model_emissions[state][0].predict_log_proba(inputs)).reshape(2)\n",
    "\n",
    "\n",
    "def reward(model, state, confidence,attack, w_a, w_r, c):\n",
    "    inputs = np.array([[confidence, attack]])\n",
    "\n",
    "    r = 0\n",
    "    for i in range(model.num_states):\n",
    "\n",
    "        r += trust_transition(model, inputs, state, i)* (reliance_prob(model, inputs,i)[0]*w_r +\n",
    "                                                         reliance_prob(model, inputs,i)[1]*w_a - attack*c)\n",
    "    return r\n",
    "        \n",
    "def reward_belief(model, belief, confidence,attack, w_a, w_r, c):\n",
    "    r = 0\n",
    "    for i in range(belief.shape[0]):\n",
    "        r += belief[i] * reward(model, i, confidence, attack, w_a, w_r, c)\n",
    "    return r\n",
    "\n",
    "def EU_max(model, belief, confidence, attack, l, w_a, w_r, c,max_length=2):\n",
    "    if l < 1:\n",
    "        print(\"error: l should be greated than 1\")\n",
    "    if l == 1:\n",
    "        eu_max = reward_belief(model, belief, confidence, attack, w_a, w_r, c)\n",
    "        return eu_max\n",
    "    else:\n",
    "        r = reward_belief(model, belief, confidence, attack, w_a, w_r, c)\n",
    "        eu_max = r \n",
    "        for d in [0,1]:\n",
    "            sum_ = 0\n",
    "            updated_b = update_belief(model, belief, confidence, attack,reliance=d)\n",
    "            for k in range(belief.shape[0]):\n",
    "                b_k = belief[k]\n",
    "                inputs = np.array([[ confidence, attack]])\n",
    "                for i in range(model.num_states):\n",
    "                    \n",
    "                    sum_ += b_k*trust_transition(model, inputs, k, i)*(reliance_prob(model,inputs,i)[d]*max(0.5*(EU_max(model, updated_b,confidence=0,attack=0,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)\n",
    "                                                                                                              +EU_max(model, updated_b,confidence=1,attack=0,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)),\n",
    "                                                                                    0.5*(EU_max(model, updated_b,confidence=0,attack=1,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c)+EU_max(model, updated_b,confidence=1,attack=1,l=min(l-1,max_length),w_a=w_a, w_r=w_r, c=c))))\n",
    "            eu_max += sum_\n",
    "        return eu_max\n",
    "\n",
    "def update_belief(model,belief, confidence, attack, reliance, constant = 1):\n",
    "    updated_b = np.zeros_like(belief)\n",
    "    inputs = np.array([[confidence, attack]])\n",
    "    for j in range(belief.shape[0]):\n",
    "        for i in range(belief.shape[0]):\n",
    "            updated_b[j] += constant*belief[i]*trust_transition(model, inputs, state_src=i,state_dst=j)*reliance_prob(model, inputs, j)[reliance]\n",
    "    return updated_b\n",
    "    \n",
    "def covxy(x,y):\n",
    "    if type(x) == list:\n",
    "        x = np.array(x)\n",
    "    if type(y) == list:\n",
    "        y = np.array(y)\n",
    "    covxy = np.mean((x - x.mean()) * (y - y.mean()))\n",
    "    return covxy\n",
    "\n",
    "def hmm_attack_helper(model, n, w_a, w_r, c, humans):\n",
    "    accept = 0\n",
    "    reject = 0\n",
    "    attack = 0\n",
    "    for h in humans:\n",
    "        b = np.array([1/model.num_states for i in range(model.num_states)])\n",
    "\n",
    "        tasks = assign_task(n)\n",
    "        for k, t in enumerate(tasks):\n",
    "            \n",
    "            action = np.argmax([EU_max(model, b, t, 0, n-k, w_a, w_r, c),EU_max(model, b, t, 1, n-k, w_a, w_r, c)])\n",
    "            \n",
    "            if t == 0 and action==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[2],h[2]])\n",
    "            elif t == 1 and action==0:\n",
    "                d = np.random.choice([0,1],p=[1-h[3],h[3]])\n",
    "            elif t == 0 and action == 1:\n",
    "                attack+= 1\n",
    "                d = np.random.choice([0,1],p=[1-h[0],h[0]])\n",
    "            else:\n",
    "                attack+=1\n",
    "                d = np.random.choice([0,1],p=[1-h[1],h[1]]) \n",
    "            b = update_belief(model, b, t,action, d)\n",
    "            if d == 1:\n",
    "                accept += 1\n",
    "            else:\n",
    "                reject += 1\n",
    "            print(accept, reject, attack)\n",
    "    return w_a * accept + w_r * reject - attack*c\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77904c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval hmm-based algorithm\n",
    "\n",
    "#1. contruct human behavior data\n",
    "hmm_data = selected_data\n",
    "behavior_data = []\n",
    "hmm_data[\"reliance\"] = hmm_data[\"reliance\"].apply(lambda x: 1 if x == True else -1)\n",
    "hmm_data[\"attack\"] = hmm_data[\"attack\"].apply(lambda x:1 if x == 0 else x)\n",
    "hmm_data[\"human_confidence\"] = hmm_data[\"human_confidence\"].apply(lambda x:-1 if x == 0 else x)\n",
    "workers = list(set(selected_data[\"workerId\"]))\n",
    "for w in workers:\n",
    "    d = hmm_data.query(\"workerId==@w\").sort_values(by=[\"taskId\"])\n",
    "    behavior_data.append(d[[\"human_confidence\",\"attack\", \"reliance\"]])\n",
    "initial_columns = [\"human_confidence\", \"attack\"]\n",
    "transition_columns = [\"human_confidence\", \"attack\"]\n",
    "decision_columns = [\"human_confidence\", \"attack\"]\n",
    "\n",
    "model = UnSupervisedIOHMM(num_states=2, max_EM_iter=200, EM_tol=1e-6)\n",
    "\n",
    "model.set_models(model_emissions = [DiscreteMNL(solver='lbfgs')], \n",
    "                model_transition=CrossEntropyMNL(solver='lbfgs'),\n",
    "                model_initial=CrossEntropyMNL(solver='lbfgs'))\n",
    "\n",
    "model.set_inputs(covariates_initial = initial_columns, covariates_transition = initial_columns, covariates_emissions = [initial_columns])\n",
    "\n",
    "model.set_outputs([['reliance']])\n",
    "\n",
    "model.set_data(behavior_data)\n",
    "model.train()\n",
    "# hmm_attack_helper(model, 20,0,0.5,0.15, test_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc7003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack cost:---->0.0\n",
      "high confidence:271.23\n",
      "half attack:305.48\n",
      "all attack:396.2\n",
      "no attack:213.44\n",
      "attack cost:---->0.01\n",
      "high confidence:264.4069999999999\n",
      "half attack:301.67000000000024\n",
      "all attack:386.0900000000004\n",
      "no attack:213.06\n",
      "attack cost:---->0.02\n",
      "high confidence:260.6772\n",
      "half attack:295.91000000000025\n",
      "all attack:377.94\n",
      "no attack:214.85\n",
      "attack cost:---->0.03\n",
      "high confidence:255.65419999999995\n",
      "half attack:290.75999999999976\n",
      "all attack:367.4700000000001\n",
      "no attack:215.73\n",
      "attack cost:---->0.04\n",
      "high confidence:248.74720000000005\n",
      "half attack:286.9699999999998\n",
      "all attack:356.8399999999997\n",
      "no attack:215.68\n",
      "attack cost:---->0.05\n",
      "high confidence:248.19\n",
      "half attack:279.54\n",
      "all attack:345.65\n",
      "no attack:215.05\n",
      "attack cost:---->0.06\n",
      "high confidence:241.00839999999997\n",
      "half attack:274.11000000000024\n",
      "all attack:336.6700000000003\n",
      "no attack:216.5\n",
      "attack cost:---->0.07\n",
      "high confidence:237.26999999999995\n",
      "half attack:272.7900000000002\n",
      "all attack:327.22999999999973\n",
      "no attack:214.88\n",
      "attack cost:---->0.08\n",
      "high confidence:231.54359999999986\n",
      "half attack:267.4299999999998\n",
      "all attack:317.77000000000027\n",
      "no attack:214.62\n",
      "attack cost:---->0.09\n",
      "high confidence:226.83700000000002\n",
      "half attack:259.5899999999998\n",
      "all attack:308.3699999999997\n",
      "no attack:215.29\n"
     ]
    }
   ],
   "source": [
    "C = [i *0.01 for i in range(10)]\n",
    "\n",
    "for c in C:\n",
    "    print(\"attack cost:---->{}\".format(c))\n",
    "    print(\"high confidence:{}\".format(eval_func(high_confidence_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"half attack:{}\".format(eval_func(half_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"all attack:{}\".format(eval_func(all_attack_helper,20,0,0.5,c, test_humans)))\n",
    "    print(\"no attack:{}\".format(eval_func(no_attack_helper, 20,0,0.5,c, test_humans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baa82d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [i *0.01 for i in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f067703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1\n",
      "0 2 2\n",
      "0 3 3\n",
      "0 4 4\n",
      "0 5 5\n",
      "1 5 6\n",
      "1 6 7\n",
      "1 7 8\n",
      "1 8 9\n",
      "1 9 10\n",
      "1 10 11\n",
      "1 11 12\n",
      "1 12 13\n",
      "1 13 14\n",
      "1 14 15\n",
      "2 14 16\n",
      "3 14 17\n",
      "3 15 18\n",
      "4 15 19\n",
      "4 16 20\n",
      "4 17 21\n",
      "4 18 22\n",
      "4 19 23\n",
      "4 20 24\n",
      "4 21 25\n",
      "4 22 26\n",
      "5 22 27\n",
      "5 23 28\n",
      "6 23 29\n",
      "6 24 30\n",
      "7 24 31\n",
      "7 25 32\n",
      "7 26 33\n",
      "7 27 34\n",
      "7 28 35\n",
      "7 29 36\n",
      "7 30 37\n",
      "7 31 38\n",
      "8 31 39\n",
      "8 32 40\n",
      "8 33 41\n",
      "8 34 42\n",
      "8 35 43\n",
      "8 36 44\n",
      "9 36 45\n",
      "9 37 46\n",
      "10 37 47\n",
      "11 37 48\n",
      "11 38 49\n",
      "11 39 50\n",
      "11 40 51\n",
      "11 41 52\n",
      "12 41 53\n",
      "12 42 54\n",
      "13 42 55\n",
      "13 43 56\n",
      "13 44 57\n",
      "13 45 58\n",
      "13 46 59\n",
      "13 47 60\n",
      "13 48 61\n",
      "13 49 62\n",
      "13 50 63\n",
      "13 51 64\n",
      "13 52 65\n",
      "14 52 66\n",
      "14 53 67\n",
      "14 54 68\n",
      "15 54 69\n",
      "15 55 70\n",
      "16 55 71\n",
      "16 56 72\n",
      "16 57 73\n",
      "16 58 74\n",
      "16 59 75\n",
      "16 60 76\n",
      "16 61 77\n",
      "17 61 78\n",
      "17 62 79\n",
      "18 62 80\n",
      "18 63 81\n",
      "18 64 82\n",
      "19 64 83\n",
      "19 65 84\n",
      "19 66 85\n",
      "19 67 86\n",
      "19 68 87\n",
      "20 68 88\n",
      "20 69 89\n",
      "21 69 90\n",
      "22 69 91\n",
      "23 69 92\n",
      "23 70 93\n",
      "24 70 94\n",
      "24 71 95\n",
      "25 71 96\n",
      "26 71 97\n",
      "26 72 98\n",
      "26 73 99\n",
      "26 74 100\n",
      "26 75 101\n",
      "26 76 102\n",
      "26 77 103\n",
      "26 78 104\n",
      "27 78 105\n",
      "27 79 106\n",
      "28 79 107\n",
      "29 79 108\n",
      "29 80 109\n",
      "29 81 110\n",
      "29 82 111\n",
      "29 83 112\n",
      "30 83 113\n",
      "30 84 114\n",
      "30 85 115\n",
      "30 86 116\n",
      "30 87 117\n",
      "30 88 118\n",
      "30 89 119\n",
      "30 90 120\n",
      "30 91 121\n",
      "30 92 122\n",
      "30 93 123\n",
      "30 94 124\n",
      "30 95 125\n",
      "31 95 126\n",
      "31 96 127\n",
      "31 97 128\n",
      "31 98 129\n",
      "31 99 130\n",
      "31 100 131\n",
      "31 101 132\n",
      "31 102 133\n",
      "32 102 134\n",
      "32 103 135\n",
      "32 104 136\n",
      "32 105 137\n",
      "32 106 138\n",
      "33 106 139\n",
      "33 107 140\n",
      "33 108 141\n",
      "33 109 142\n",
      "33 110 143\n",
      "33 111 144\n",
      "33 112 145\n",
      "33 113 146\n",
      "33 114 147\n",
      "33 115 148\n",
      "33 116 149\n",
      "33 117 150\n",
      "34 117 151\n",
      "34 118 152\n",
      "34 119 153\n",
      "34 120 154\n",
      "35 120 155\n",
      "35 121 156\n",
      "35 122 157\n",
      "35 123 158\n",
      "35 124 159\n",
      "35 125 160\n",
      "35 126 161\n",
      "35 127 162\n",
      "35 128 163\n",
      "35 129 164\n",
      "35 130 165\n",
      "35 131 166\n",
      "35 132 167\n",
      "35 133 168\n",
      "35 134 169\n",
      "35 135 170\n",
      "35 136 171\n",
      "35 137 172\n",
      "35 138 173\n",
      "35 139 174\n",
      "35 140 175\n",
      "35 141 176\n",
      "35 142 177\n",
      "35 143 178\n",
      "35 144 179\n",
      "35 145 180\n",
      "35 146 181\n",
      "35 147 182\n",
      "35 148 183\n",
      "35 149 184\n",
      "35 150 185\n",
      "36 150 186\n",
      "36 151 187\n",
      "37 151 188\n",
      "38 151 189\n",
      "38 152 190\n",
      "39 152 191\n",
      "39 153 192\n",
      "39 154 193\n",
      "40 154 194\n",
      "40 155 195\n",
      "40 156 196\n",
      "41 156 197\n",
      "41 157 198\n",
      "41 158 199\n",
      "41 159 200\n",
      "41 160 201\n",
      "42 160 202\n",
      "42 161 203\n",
      "42 162 204\n",
      "42 163 205\n",
      "43 163 206\n",
      "44 163 207\n",
      "44 164 208\n",
      "45 164 209\n",
      "45 165 210\n",
      "45 166 211\n",
      "46 166 212\n",
      "46 167 213\n",
      "46 168 214\n",
      "46 169 215\n",
      "46 170 216\n",
      "47 170 217\n",
      "47 171 218\n",
      "48 171 219\n",
      "48 172 220\n",
      "48 173 221\n",
      "48 174 222\n",
      "48 175 223\n",
      "48 176 224\n",
      "48 177 225\n",
      "48 178 226\n",
      "48 179 227\n",
      "48 180 228\n",
      "48 181 229\n",
      "48 182 230\n",
      "48 183 231\n",
      "48 184 232\n",
      "48 185 233\n",
      "48 186 234\n",
      "48 187 235\n",
      "48 188 236\n",
      "48 189 237\n",
      "49 189 238\n",
      "49 190 239\n",
      "49 191 240\n",
      "50 191 241\n",
      "51 191 242\n",
      "51 192 243\n",
      "51 193 244\n",
      "51 194 245\n",
      "52 194 246\n",
      "53 194 247\n",
      "53 195 248\n",
      "53 196 249\n",
      "54 196 250\n",
      "54 197 251\n",
      "54 198 252\n",
      "54 199 253\n",
      "54 200 254\n",
      "55 200 255\n",
      "55 201 256\n",
      "55 202 257\n",
      "55 203 258\n",
      "55 204 259\n",
      "55 205 260\n",
      "55 206 261\n",
      "55 207 262\n",
      "55 208 263\n",
      "56 208 264\n",
      "57 208 265\n",
      "58 208 266\n",
      "59 208 267\n",
      "60 208 268\n",
      "60 209 269\n",
      "60 210 270\n",
      "61 210 271\n",
      "62 210 272\n",
      "62 211 273\n",
      "62 212 274\n",
      "62 213 275\n",
      "62 214 276\n",
      "63 214 277\n",
      "63 215 278\n",
      "64 215 279\n",
      "64 216 280\n",
      "64 217 281\n",
      "64 218 282\n",
      "64 219 283\n",
      "64 220 284\n",
      "64 221 285\n",
      "64 222 286\n",
      "64 223 287\n",
      "64 224 288\n",
      "64 225 289\n",
      "64 226 290\n",
      "64 227 291\n",
      "64 228 292\n",
      "65 228 293\n",
      "66 228 294\n",
      "67 228 295\n",
      "68 228 296\n",
      "68 229 297\n",
      "68 230 298\n",
      "68 231 299\n",
      "69 231 300\n",
      "69 232 301\n",
      "69 233 302\n",
      "69 234 303\n",
      "69 235 304\n",
      "69 236 305\n",
      "69 237 306\n",
      "70 237 307\n",
      "70 238 308\n",
      "71 238 309\n",
      "71 239 310\n",
      "71 240 311\n",
      "71 241 312\n",
      "71 242 313\n",
      "72 242 314\n",
      "72 243 315\n",
      "73 243 316\n",
      "73 244 317\n",
      "73 245 318\n",
      "73 246 319\n",
      "73 247 320\n",
      "73 248 321\n",
      "73 249 322\n",
      "73 250 323\n",
      "73 251 324\n",
      "73 252 325\n",
      "73 253 326\n",
      "73 254 327\n",
      "73 255 328\n",
      "74 255 329\n",
      "74 256 330\n",
      "74 257 331\n",
      "74 258 332\n",
      "74 259 333\n",
      "75 259 334\n",
      "75 260 335\n",
      "75 261 336\n",
      "75 262 337\n",
      "75 263 338\n",
      "75 264 339\n",
      "75 265 340\n",
      "75 266 341\n",
      "75 267 342\n",
      "75 268 343\n",
      "75 269 344\n",
      "75 270 345\n",
      "75 271 346\n",
      "75 272 347\n",
      "75 273 348\n",
      "75 274 349\n",
      "75 275 350\n",
      "75 276 351\n",
      "75 277 352\n",
      "75 278 353\n",
      "75 279 354\n",
      "75 280 355\n",
      "76 280 356\n",
      "76 281 357\n",
      "76 282 358\n",
      "76 283 359\n",
      "76 284 360\n",
      "76 285 361\n",
      "76 286 362\n",
      "76 287 363\n",
      "76 288 364\n",
      "76 289 365\n",
      "76 290 366\n",
      "76 291 367\n",
      "76 292 368\n",
      "76 293 369\n",
      "77 293 370\n",
      "77 294 371\n",
      "77 295 372\n",
      "77 296 373\n",
      "77 297 374\n",
      "77 298 375\n",
      "77 299 376\n",
      "78 299 377\n",
      "79 299 378\n",
      "79 300 379\n",
      "80 300 380\n",
      "81 300 381\n",
      "82 300 382\n",
      "82 301 383\n",
      "82 302 384\n",
      "82 303 385\n",
      "83 303 386\n",
      "84 303 387\n",
      "84 304 388\n",
      "85 304 389\n",
      "85 305 390\n",
      "85 306 391\n",
      "86 306 392\n",
      "86 307 393\n",
      "86 308 394\n",
      "87 308 395\n",
      "87 309 396\n",
      "87 310 397\n",
      "87 311 398\n",
      "88 311 399\n",
      "89 311 400\n",
      "89 312 401\n",
      "89 313 402\n",
      "89 314 403\n",
      "90 314 404\n",
      "90 315 405\n",
      "91 315 406\n",
      "91 316 407\n",
      "91 317 408\n",
      "91 318 409\n",
      "91 319 410\n",
      "91 320 411\n",
      "91 321 412\n",
      "91 322 413\n",
      "91 323 414\n",
      "91 324 415\n",
      "92 324 416\n",
      "92 325 417\n",
      "92 326 418\n",
      "93 326 419\n",
      "93 327 420\n",
      "94 327 421\n",
      "94 328 422\n",
      "95 328 423\n",
      "95 329 424\n",
      "95 330 425\n",
      "95 331 426\n",
      "95 332 427\n",
      "95 333 428\n",
      "96 333 429\n",
      "97 333 430\n",
      "97 334 431\n",
      "97 335 432\n",
      "98 335 433\n",
      "99 335 434\n",
      "100 335 435\n",
      "100 336 436\n",
      "101 336 437\n",
      "101 337 438\n",
      "102 337 439\n",
      "103 337 440\n",
      "103 338 441\n",
      "103 339 442\n",
      "103 340 443\n",
      "104 340 444\n",
      "104 341 445\n",
      "105 341 446\n",
      "105 342 447\n",
      "105 343 448\n",
      "105 344 449\n",
      "106 344 450\n",
      "106 345 451\n",
      "106 346 452\n",
      "106 347 453\n",
      "106 348 454\n",
      "106 349 455\n",
      "106 350 456\n",
      "106 351 457\n",
      "106 352 458\n",
      "107 352 459\n",
      "107 353 460\n",
      "107 354 461\n",
      "107 355 462\n",
      "107 356 463\n",
      "107 357 464\n",
      "107 358 465\n",
      "107 359 466\n",
      "107 360 467\n",
      "107 361 468\n",
      "108 361 469\n",
      "108 362 470\n",
      "108 363 471\n",
      "109 363 472\n",
      "109 364 473\n",
      "109 365 474\n",
      "109 366 475\n",
      "109 367 476\n",
      "109 368 477\n",
      "109 369 478\n",
      "110 369 479\n",
      "110 370 480\n",
      "110 371 481\n",
      "110 372 482\n",
      "110 373 483\n",
      "110 374 484\n",
      "111 374 485\n",
      "111 375 486\n",
      "111 376 487\n",
      "111 377 488\n",
      "111 378 489\n",
      "111 379 490\n",
      "112 379 491\n",
      "113 379 492\n",
      "113 380 493\n",
      "114 380 494\n",
      "114 381 495\n",
      "114 382 496\n",
      "114 383 497\n",
      "114 384 498\n",
      "114 385 499\n",
      "114 386 500\n",
      "114 387 501\n",
      "114 388 502\n",
      "114 389 503\n",
      "114 390 504\n",
      "114 391 505\n",
      "114 392 506\n",
      "115 392 507\n",
      "115 393 508\n",
      "115 394 509\n",
      "115 395 510\n",
      "115 396 511\n",
      "116 396 512\n",
      "116 397 513\n",
      "116 398 514\n",
      "116 399 515\n",
      "116 400 516\n",
      "116 401 517\n",
      "116 402 518\n",
      "116 403 519\n",
      "117 403 520\n",
      "118 403 521\n",
      "118 404 522\n",
      "118 405 523\n",
      "118 406 524\n",
      "118 407 525\n",
      "118 408 526\n",
      "118 409 527\n",
      "118 410 528\n",
      "118 411 529\n",
      "118 412 530\n",
      "118 413 531\n",
      "118 414 532\n",
      "118 415 533\n",
      "118 416 534\n",
      "118 417 535\n",
      "118 418 536\n",
      "118 419 537\n",
      "118 420 538\n",
      "118 421 539\n",
      "118 422 540\n",
      "118 423 541\n",
      "119 423 542\n",
      "120 423 543\n",
      "121 423 544\n",
      "122 423 545\n",
      "122 424 546\n",
      "122 425 547\n",
      "122 426 548\n",
      "122 427 549\n",
      "122 428 550\n",
      "122 429 551\n",
      "123 429 552\n",
      "124 429 553\n",
      "124 430 554\n",
      "125 430 555\n",
      "125 431 556\n",
      "126 431 557\n",
      "127 431 558\n",
      "128 431 559\n",
      "129 431 560\n",
      "129 432 561\n",
      "129 433 562\n",
      "129 434 563\n",
      "129 435 564\n",
      "129 436 565\n",
      "129 437 566\n",
      "129 438 567\n",
      "129 439 568\n",
      "129 440 569\n",
      "129 441 570\n",
      "129 442 571\n",
      "129 443 572\n",
      "130 443 573\n",
      "131 443 574\n",
      "131 444 575\n",
      "131 445 576\n",
      "131 446 577\n",
      "132 446 578\n",
      "132 447 579\n",
      "132 448 580\n",
      "132 449 581\n",
      "132 450 582\n",
      "132 451 583\n",
      "133 451 584\n",
      "133 452 585\n",
      "133 453 586\n",
      "133 454 587\n",
      "133 455 588\n",
      "133 456 589\n",
      "133 457 590\n",
      "133 458 591\n",
      "133 459 592\n",
      "134 459 593\n",
      "134 460 594\n",
      "134 461 595\n",
      "134 462 596\n",
      "135 462 597\n",
      "135 463 598\n",
      "136 463 599\n",
      "136 464 600\n",
      "136 465 601\n",
      "136 466 602\n",
      "136 467 603\n",
      "136 468 604\n",
      "137 468 605\n",
      "137 469 606\n",
      "137 470 607\n",
      "138 470 608\n",
      "138 471 609\n",
      "138 472 610\n",
      "138 473 611\n",
      "139 473 612\n",
      "140 473 613\n",
      "140 474 614\n",
      "140 475 615\n",
      "141 475 616\n",
      "142 475 617\n",
      "142 476 618\n",
      "143 476 619\n",
      "143 477 620\n",
      "143 478 621\n",
      "143 479 622\n",
      "143 480 623\n",
      "143 481 624\n",
      "143 482 625\n",
      "143 483 626\n",
      "144 483 627\n",
      "144 484 628\n",
      "144 485 629\n",
      "144 486 630\n",
      "144 487 631\n",
      "145 487 632\n",
      "145 488 633\n",
      "145 489 634\n",
      "145 490 635\n",
      "145 491 636\n",
      "145 492 637\n",
      "145 493 638\n",
      "145 494 639\n",
      "145 495 640\n",
      "145 496 641\n",
      "145 497 642\n",
      "145 498 643\n",
      "146 498 644\n",
      "146 499 645\n",
      "146 500 646\n",
      "146 501 647\n",
      "146 502 648\n",
      "146 503 649\n",
      "146 504 650\n",
      "146 505 651\n",
      "146 506 652\n",
      "146 507 653\n",
      "146 508 654\n",
      "146 509 655\n",
      "147 509 656\n",
      "147 510 657\n",
      "147 511 658\n",
      "147 512 659\n",
      "148 512 660\n",
      "148 513 661\n",
      "148 514 662\n",
      "148 515 663\n",
      "148 516 664\n",
      "148 517 665\n",
      "148 518 666\n",
      "148 519 667\n",
      "148 520 668\n",
      "148 521 669\n",
      "148 522 670\n",
      "148 523 671\n",
      "148 524 672\n",
      "148 525 673\n",
      "148 526 674\n",
      "148 527 675\n",
      "148 528 676\n",
      "148 529 677\n",
      "148 530 678\n",
      "148 531 679\n",
      "148 532 680\n",
      "148 533 681\n",
      "148 534 682\n",
      "148 535 683\n",
      "148 536 684\n",
      "148 537 685\n",
      "148 538 686\n",
      "148 539 687\n",
      "148 540 688\n",
      "148 541 689\n",
      "148 542 690\n",
      "148 543 691\n",
      "148 544 692\n",
      "148 545 693\n",
      "148 546 694\n",
      "148 547 695\n",
      "148 548 696\n",
      "148 549 697\n",
      "148 550 698\n",
      "148 551 699\n",
      "148 552 700\n",
      "148 553 701\n",
      "148 554 702\n",
      "148 555 703\n",
      "148 556 704\n",
      "149 556 705\n",
      "149 557 706\n",
      "150 557 707\n",
      "150 558 708\n",
      "151 558 709\n",
      "151 559 710\n",
      "151 560 711\n",
      "152 560 712\n",
      "152 561 713\n",
      "153 561 714\n",
      "153 562 715\n",
      "154 562 716\n",
      "154 563 717\n",
      "154 564 718\n",
      "154 565 719\n",
      "154 566 720\n",
      "154 567 721\n",
      "154 568 722\n",
      "154 569 723\n",
      "154 570 724\n",
      "154 571 725\n",
      "154 572 726\n",
      "154 573 727\n",
      "154 574 728\n",
      "154 575 729\n",
      "154 576 730\n",
      "154 577 731\n",
      "154 578 732\n",
      "154 579 733\n",
      "154 580 734\n",
      "154 581 735\n",
      "155 581 736\n",
      "155 582 737\n",
      "155 583 738\n",
      "155 584 739\n",
      "155 585 740\n",
      "155 586 741\n",
      "155 587 742\n",
      "155 588 743\n",
      "155 589 744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 590 745\n",
      "155 591 746\n",
      "155 592 747\n",
      "155 593 748\n",
      "155 594 749\n",
      "156 594 750\n",
      "156 595 751\n",
      "156 596 752\n",
      "156 597 753\n",
      "156 598 754\n",
      "156 599 755\n",
      "156 600 756\n",
      "156 601 757\n",
      "156 602 758\n",
      "156 603 759\n",
      "156 604 760\n",
      "156 605 761\n",
      "156 606 762\n",
      "156 607 763\n",
      "156 608 764\n",
      "156 609 765\n",
      "156 610 766\n",
      "156 611 767\n",
      "156 612 768\n",
      "156 613 769\n",
      "156 614 770\n",
      "156 615 771\n",
      "156 616 772\n",
      "156 617 773\n",
      "156 618 774\n",
      "156 619 775\n",
      "156 620 776\n",
      "156 621 777\n",
      "156 622 778\n",
      "156 623 779\n",
      "157 623 780\n",
      "157 624 781\n",
      "157 625 782\n",
      "157 626 783\n",
      "157 627 784\n",
      "157 628 785\n",
      "157 629 786\n",
      "157 630 787\n",
      "157 631 788\n",
      "157 632 789\n",
      "157 633 790\n",
      "157 634 791\n",
      "157 635 792\n",
      "157 636 793\n",
      "157 637 794\n",
      "157 638 795\n",
      "157 639 796\n",
      "157 640 797\n",
      "157 641 798\n",
      "157 642 799\n",
      "157 643 800\n",
      "158 643 801\n",
      "158 644 802\n",
      "158 645 803\n",
      "158 646 804\n",
      "159 646 805\n",
      "160 646 806\n",
      "160 647 807\n",
      "160 648 808\n",
      "160 649 809\n",
      "160 650 810\n",
      "161 650 811\n",
      "162 650 812\n",
      "162 651 813\n",
      "162 652 814\n",
      "162 653 815\n",
      "163 653 816\n",
      "163 654 817\n",
      "164 654 818\n",
      "164 655 819\n",
      "165 655 820\n",
      "165 656 821\n",
      "165 657 822\n",
      "165 658 823\n",
      "165 659 824\n",
      "165 660 825\n",
      "165 661 826\n",
      "165 662 827\n",
      "165 663 828\n",
      "165 664 829\n",
      "165 665 830\n",
      "165 666 831\n",
      "165 667 832\n",
      "165 668 833\n",
      "165 669 834\n",
      "165 670 835\n",
      "165 671 836\n",
      "165 672 837\n",
      "165 673 838\n",
      "165 674 839\n",
      "165 675 840\n",
      "165 676 841\n",
      "165 677 842\n",
      "165 678 843\n",
      "165 679 844\n",
      "165 680 845\n",
      "165 681 846\n",
      "166 681 847\n",
      "166 682 848\n",
      "166 683 849\n",
      "166 684 850\n",
      "166 685 851\n",
      "166 686 852\n",
      "167 686 853\n",
      "167 687 854\n",
      "167 688 855\n",
      "167 689 856\n",
      "167 690 857\n",
      "167 691 858\n",
      "167 692 859\n",
      "168 692 860\n",
      "169 692 861\n",
      "170 692 862\n",
      "170 693 863\n",
      "170 694 864\n",
      "170 695 865\n",
      "170 696 866\n",
      "170 697 867\n",
      "171 697 868\n",
      "172 697 869\n",
      "172 698 870\n",
      "172 699 871\n",
      "172 700 872\n",
      "172 701 873\n",
      "173 701 874\n",
      "174 701 875\n",
      "175 701 876\n",
      "175 702 877\n",
      "175 703 878\n",
      "176 703 879\n",
      "176 704 880\n",
      "177 704 881\n",
      "177 705 882\n",
      "177 706 883\n",
      "177 707 884\n",
      "178 707 885\n",
      "179 707 886\n",
      "179 708 887\n",
      "179 709 888\n",
      "180 709 889\n",
      "180 710 890\n",
      "180 711 891\n",
      "180 712 892\n",
      "180 713 893\n",
      "180 714 894\n",
      "181 714 895\n",
      "181 715 896\n",
      "182 715 897\n",
      "182 716 898\n",
      "182 717 899\n",
      "183 717 900\n",
      "183 718 901\n",
      "183 719 902\n",
      "183 720 903\n",
      "183 721 904\n",
      "183 722 905\n",
      "183 723 906\n",
      "183 724 907\n",
      "183 725 908\n",
      "183 726 909\n",
      "183 727 910\n",
      "183 728 911\n",
      "183 729 912\n",
      "183 730 913\n",
      "183 731 914\n",
      "183 732 915\n",
      "183 733 916\n",
      "183 734 917\n",
      "183 735 918\n",
      "183 736 919\n",
      "183 737 920\n",
      "184 737 921\n",
      "184 738 922\n",
      "184 739 923\n",
      "184 740 924\n",
      "184 741 925\n",
      "184 742 926\n",
      "184 743 927\n",
      "184 744 928\n",
      "184 745 929\n",
      "184 746 930\n",
      "184 747 931\n",
      "184 748 932\n",
      "185 748 933\n",
      "185 749 934\n",
      "185 750 935\n",
      "185 751 936\n",
      "185 752 937\n",
      "185 753 938\n",
      "185 754 939\n",
      "185 755 940\n",
      "185 756 941\n",
      "185 757 942\n",
      "186 757 943\n",
      "187 757 944\n",
      "188 757 945\n",
      "188 758 946\n",
      "189 758 947\n",
      "189 759 948\n",
      "189 760 949\n",
      "189 761 950\n",
      "189 762 951\n",
      "189 763 952\n",
      "189 764 953\n",
      "189 765 954\n",
      "189 766 955\n",
      "189 767 956\n",
      "189 768 957\n",
      "189 769 958\n",
      "189 770 959\n",
      "189 771 960\n",
      "189 772 961\n",
      "189 773 962\n",
      "189 774 963\n",
      "190 774 964\n",
      "190 775 965\n",
      "190 776 966\n",
      "190 777 967\n",
      "190 778 968\n",
      "190 779 969\n",
      "190 780 970\n",
      "190 781 971\n",
      "190 782 972\n",
      "190 783 973\n",
      "190 784 974\n",
      "190 785 975\n",
      "190 786 976\n",
      "190 787 977\n",
      "190 788 978\n",
      "190 789 979\n",
      "190 790 980\n",
      "cost:0.01, utility:385.2\n",
      "0 1 1\n",
      "0 2 2\n",
      "0 3 3\n",
      "0 4 4\n",
      "1 4 5\n",
      "1 5 6\n",
      "1 6 7\n",
      "1 7 8\n",
      "1 8 9\n",
      "1 9 10\n",
      "1 10 11\n",
      "1 11 12\n",
      "2 11 13\n",
      "2 12 14\n",
      "3 12 15\n",
      "3 13 16\n",
      "3 14 17\n",
      "4 14 18\n",
      "4 15 19\n",
      "4 16 20\n",
      "4 17 21\n",
      "4 18 22\n",
      "4 19 23\n",
      "5 19 24\n",
      "5 20 25\n",
      "6 20 26\n",
      "6 21 27\n",
      "6 22 28\n"
     ]
    }
   ],
   "source": [
    "for c in C:\n",
    "    print(\"cost:{}, utility:{}\".format(c, hmm_attack_helper(model, 20,0,0.5,c, test_humans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f7031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive",
   "language": "python",
   "name": "interactive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
