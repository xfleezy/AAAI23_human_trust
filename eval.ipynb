{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4023e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from hmm import UnSupervisedIOHMM, SemiSupervisedIOHMM\n",
    "# from hmm import OLS,DiscreteMNL, CrossEntropyMNL\n",
    "\n",
    "import re\n",
    "import copy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class human(object):\n",
    "    def __init__(self, data=0, demo=0, ini_trust=0, mid_trust=0, final_trust=None):\n",
    "        self.data = data\n",
    "        self.demo = demo\n",
    "        self.ini_trust = ini_trust\n",
    "        self.mid_trust = mid_trust\n",
    "        self.final_trust = final_trust\n",
    "        \n",
    "def string_process(string):\n",
    "    res = re.sub(r'[^\\w\\s]', '', string)\n",
    "    return res.lower()\n",
    "\n",
    "def normalize(raw_data):\n",
    "    data = copy.copy(raw_data)\n",
    "    min_max_scalar = preprocessing.MinMaxScaler()\n",
    "    for elem in data.columns:\n",
    "        elem_values = data[elem].values\n",
    "        temp_scaled = min_max_scalar.fit_transform(elem_values.reshape((len(elem_values),1)))\n",
    "        data[elem] = temp_scaled\n",
    "    return data\n",
    "        \n",
    "def one_hot(onehot_data):\n",
    "    res = []\n",
    "    # le encoder and enc encoder\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    feature_label = [list(set(elem)) for elem in onehot_data.values.transpose()]\n",
    "    for i in range(len(onehot_data.columns)):\n",
    "        # fit and transform\n",
    "        le.fit(feature_label[i])\n",
    "        le_transform = le.transform(onehot_data[onehot_data.columns[i]])\n",
    "        set_le_transform = np.array(list(set(le_transform)))\n",
    "        enc.fit(set_le_transform.reshape((len(set_le_transform),1)))\n",
    "        res.append(enc.transform(le_transform.reshape((len(le_transform),1))))\n",
    "    one_hot_df_list = [pd.DataFrame(elem.toarray()) for elem in res]\n",
    "    onehot_feature = onehot_data.columns\n",
    "    for i in range(len(onehot_feature)):\n",
    "        for cag in one_hot_df_list[i].columns:\n",
    "            one_hot_df_list[i] = one_hot_df_list[i].rename(columns={cag:onehot_feature[i]+str(cag)})\n",
    "    one_hot_df = pd.concat(one_hot_df_list,axis=1)\n",
    "    return one_hot_df\n",
    "        \n",
    "    \n",
    "\n",
    "ini_s = pd.read_json(\"./data/initialSurvey_0503_01.json\", lines=True)\n",
    "mid_s = pd.read_json(\"./data/misSurvey_0503_01.json\", lines=True)\n",
    "fin_s = pd.read_json(\"./data/surveys_0503_01.json\", lines=True)\n",
    "data = pd.read_json(\"./data/pilotStudy_0503_01.json\", lines=True)\n",
    "data_pool = pd.read_csv(\"./data/sample_data_0329.csv\")\n",
    "low_risk = data.query(\"treatment==0\")\n",
    "high_risk = data.query(\"treatment==1\")\n",
    "data = pd.concat([low_risk, high_risk], axis=0)\n",
    "fin_s[\"gender\"] = fin_s[\"gender\"].apply(lambda x:\"female\" if x==1 else \"male\")\n",
    "for i in data_pool:\n",
    "    data_pool.loc[(data_pool['age'] > 16) & (data_pool['age'] <= 25), 'age'] = 1\n",
    "    data_pool.loc[(data_pool['age'] > 25) & (data_pool['age'] <= 32), 'age'] = 2\n",
    "    data_pool.loc[(data_pool['age'] > 32) & (data_pool['age'] <= 40), 'age'] = 3\n",
    "    data_pool.loc[(data_pool['age'] > 40) & (data_pool['age'] <= 50), 'age'] = 4\n",
    "    data_pool.loc[data_pool['age'] > 50, 'age'] = 5\n",
    "    \n",
    "label = data_pool[[\"income\",\"ml_pred\",\"id\"]]\n",
    "data_pool = data_pool.drop([\"income\",\"ml_pred\",\"id\"], axis=1)\n",
    "numerical_var = [c for c in data_pool.columns if data_pool[c].dtype !=object]\n",
    "string_var = [c for c in data_pool.columns if data_pool[c].dtype == object]\n",
    "data_pool = data_pool[data_pool.columns]\n",
    "numerical_data = data_pool[numerical_var]\n",
    "string_data = data_pool[string_var]\n",
    "string_feature =one_hot(string_data)\n",
    "numerical_feature = normalize(numerical_data)\n",
    "string_feature.index = numerical_feature.index\n",
    "data_pool = pd.concat([numerical_feature, string_feature,label],axis=1)\n",
    "process_data = {}\n",
    "# treatment = {0:[],1:[]}\n",
    "demo_information = fin_s[[\"gender\",\"age\",\"education\",\"programming\"]]\n",
    "numerical_var = [c for c in demo_information.columns if demo_information[c].dtype != object]\n",
    "# string_var = [c for c in demo_information.columns if demo_information[c].dtype == object]\n",
    "string_var = [c for c in demo_information.columns]\n",
    "numerical_data = demo_information[numerical_var]\n",
    "string_data = demo_information[string_var]\n",
    "string_feature =one_hot(string_data)\n",
    "numerical_feature = normalize(numerical_data)\n",
    "string_feature.index = numerical_feature.index\n",
    "# demo_information = pd.concat([numerical_feature, string_feature],axis=1)\n",
    "demo_information = string_feature\n",
    "# print(demo_information.columns)\n",
    "fin_s = fin_s.drop([\"gender\",\"age\",\"education\",\"programming\"],axis=1)\n",
    "fin_s = pd.concat([fin_s,demo_information],axis=1)\n",
    "fin_s = fin_s.rename(columns={\"age\": \"age1\"})\n",
    "fin_s[fin_s[\"trust\"].isna()]\n",
    "# fin_user = set(fin_s[~fin_s[\"trust\"].isna()][\"workerId\"])\n",
    "mid_user = set(mid_s[~mid_s[\"trust\"].isna()][\"workerId\"])\n",
    "ini_user = set(ini_s[~ini_s[\"trust\"].isna()][\"workerId\"])\n",
    "user = set(data[~data[\"globalId\"].isna()][\"workerId\"])\n",
    "user = list(user & mid_user & ini_user)\n",
    "\n",
    "for i in user:\n",
    "    u = human()\n",
    "    interaction = data.query(\"workerId==@i\")\n",
    "    if len(interaction.query(\"globalId==-1\")[\"attentionCorrect\"]) == 1:\n",
    "        if interaction.query(\"globalId==-1\")[\"attentionCorrect\"].item() == 1:\n",
    "            interaction = interaction[interaction[\"globalId\"]!=-1]\n",
    "            interaction = interaction.sort_values(by=[\"taskId\"])\n",
    "            input_task = pd.DataFrame(columns=list(data_pool.columns))\n",
    "\n",
    "        #     ml_effect = (interaction[\"income\"] == interaction[\"mlPrediction\"]).apply(lambda x:1 if x else -1)\n",
    "            for k in range(21):\n",
    "                instance = interaction.query(\"taskId==@k\")\n",
    "                globalId = instance[\"globalId\"]\n",
    "                if not globalId.empty:\n",
    "                    globalId = int(globalId.iloc[0].item())\n",
    "                    task_feature = data_pool[data_pool[\"id\"]==globalId]\n",
    "                    input_task.loc[k] = task_feature.loc[task_feature.index.item()]\n",
    "                   \n",
    "            ml_effect = (input_task[\"income\"] == input_task[\"ml_pred\"]).apply(lambda x:1 if x else -1)\n",
    "            ml_effect = pd.DataFrame({'ml_effect': [1] + list(ml_effect.values)[:19]})\n",
    "            treatment = pd.DataFrame({'treatment':interaction[\"treatment\"]})\n",
    "            human_decision = pd.DataFrame({'decision':(interaction[\"mlPrediction\"] == interaction[\"prediction\"]).apply(lambda x:1 if x else 0)})\n",
    "            human_correct = pd.DataFrame({'correct':(interaction[\"prediction\"] == interaction[\"income\"]).apply(lambda x:1 if x else 0)})\n",
    "            decision_effect = human_correct[\"correct\"].apply(lambda x:1 if x==1 else -1)\n",
    "            decision_effect = pd.DataFrame({'correct_effect': [1] + list(decision_effect.values)[:19]})\n",
    "            last_decision = human_decision[\"decision\"]\n",
    "            last_decision = pd.DataFrame({'last_decision': [1] + list(last_decision.values)[:19]})\n",
    "            if len(ml_effect) == 20 and len(input_task)==20 and len(human_decision) ==20:\n",
    "#                 ml_effect.index = input_task.index\n",
    "#                 human_decision.index = input_task.index\n",
    "#                 human_correct.index = input_task.index\n",
    "#                 decision_effect.index = input_task.index\n",
    "#                 last_decision.index = input_task.index\n",
    "#                 input_task = pd.concat([input_task,ml_effect,human_decision,human_correct,decision_effect,last_decision],axis=1)\n",
    "#                 u.data = input_task\n",
    "#                 treatment[list(interaction[\"treatment\"])[0]].append(i)\n",
    "                if len(mid_s.query(\"workerId==@i\")[\"trust\"]) == 1 and len(ini_s.query(\"workerId==@i\")[\"trust\"])==1 and not fin_s.query(\"workerId==@i\").empty:\n",
    "                    ini_user = ini_s.query(\"workerId==@i\")[\"trust\"].item()\n",
    "                    mid_user = mid_s.query(\"workerId==@i\")[\"trust\"].item()\n",
    "                    pos = mid_s.query(\"workerId==@i\")[\"taskId\"].item()\n",
    "                    fin_user = fin_s.query(\"workerId==@i\")[demo_information.columns]\n",
    "                    demo_feature = pd.concat([i for i in [fin_user]*20],axis=0)\n",
    "                    treatment.index = input_task.index\n",
    "                    demo_feature.index = input_task.index\n",
    "                    ml_effect.index = input_task.index\n",
    "                    human_decision.index = input_task.index\n",
    "                    human_correct.index = input_task.index\n",
    "                    decision_effect.index = input_task.index\n",
    "                    last_decision.index = input_task.index\n",
    "                    input_task = pd.concat([input_task,ml_effect,human_decision,human_correct,decision_effect,last_decision,demo_feature,treatment],axis=1)\n",
    "                    u.data = input_task\n",
    "                    # modify gender feature\n",
    "                    if ini_user <=2:\n",
    "                        ini_user = 0\n",
    "                    elif ini_user == 3:\n",
    "                        ini_user = 1\n",
    "                    else:\n",
    "                        ini_user = 2\n",
    "                    u.ini_trust = ini_user\n",
    "                    if mid_user <=2:\n",
    "                        mid_user = 0\n",
    "                    elif mid_user == 3:\n",
    "                        mid_user = 1\n",
    "                    else:\n",
    "                        mid_user = 2\n",
    "                    u.mid_trust = [mid_user,pos]\n",
    "                    u.demo = fin_user\n",
    "                    u.data = input_task\n",
    "                    process_data[i] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58511a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fivefold(index):\n",
    "    random.shuffle(index)\n",
    "    interval = len(index)//5\n",
    "    l = []\n",
    "    for i in range(5):\n",
    "        if i == 4:\n",
    "            l.append(index[i*interval:])\n",
    "        else:\n",
    "            l.append(index[i*interval:(i+1)*interval])\n",
    "    fold = []\n",
    "    for i in range(5):\n",
    "        test = l[i]\n",
    "        train = [l[k] for k in range(5) if k!=i]\n",
    "        e = []\n",
    "        for t in train:\n",
    "            e += t\n",
    "        train = e\n",
    "        fold.append([train,test])\n",
    "    return fold\n",
    "\n",
    "\n",
    "def generate_test(test_data, feature_columns):\n",
    "    low_risk = {\"test_data\":[], \"test_Y\":[]}\n",
    "    high_risk = {\"test_data\":[], \"test_Y\":[]}\n",
    "    for d in test_data:\n",
    "        if d[\"treatment\"][0] == 0:\n",
    "            low_risk[\"test_data\"].append(d[feature_columns])\n",
    "            low_risk[\"test_Y\"].append(d[\"decision\"])\n",
    "        else:\n",
    "            high_risk[\"test_data\"].append(d[feature_columns])\n",
    "            high_risk[\"test_Y\"].append(d[\"decision\"])\n",
    "    return low_risk, high_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3769d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import OLS,DiscreteMNL, CrossEntropyMNL\n",
    "from hmm import Trust_hmm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9553e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "feedback = [\"treatment\",'ml_effect','correct_effect']\n",
    "demo = ['gender0', 'gender1', 'age0', 'age1', 'age2', 'age3', 'age4', 'age5',\n",
    "           'education0', 'education1', 'education2', 'education3', 'education4',\n",
    "           'programming0', 'programming1', 'programming2', 'programming3']\n",
    "context = ['age', 'education.num', 'hours.per.week', 'workclass0', 'workclass1', \n",
    "           'workclass2', 'marital.status0', 'marital.status1', 'marital.status2',\n",
    "           'occupation0', 'occupation1', 'occupation2', 'occupation3',\n",
    "           'occupation4', 'occupation5', 'occupation6', 'occupation7',\n",
    "           'occupation8', 'occupation9', 'occupation10', 'occupation11', 'sex0',\n",
    "           'sex1']\n",
    "\n",
    "feature_columns = ['age', 'education.num', 'hours.per.week', 'workclass0', 'workclass1', \n",
    "           'workclass2', 'marital.status0', 'marital.status1', 'marital.status2',\n",
    "           'occupation0', 'occupation1', 'occupation2', 'occupation3',\n",
    "           'occupation4','ml_effect', 'correct_effect', 'occupation5', 'occupation6', 'occupation7',\n",
    "           'occupation8', 'occupation9', 'occupation10', 'occupation11', 'sex0',\n",
    "           'sex1','gender0', 'gender1', 'age0', 'age1', 'age2', 'age3', 'age4', 'age5',\n",
    "           'education0', 'education1', 'education2', 'education3', 'education4',\n",
    "           'programming0', 'programming1', 'programming2', 'programming3','treatment']\n",
    "\n",
    "initial_columns = feedback + demo + context\n",
    "transition_columns = feedback + context\n",
    "decision_columns = feedback + context\n",
    "\n",
    "\n",
    "def fivefold(index):\n",
    "    random.shuffle(index)\n",
    "    interval = len(index)//5\n",
    "    l = []\n",
    "    for i in range(5):\n",
    "        if i == 4:\n",
    "            l.append(index[i*interval:])\n",
    "        else:\n",
    "            l.append(index[i*interval:(i+1)*interval])\n",
    "    fold = []\n",
    "    for i in range(5):\n",
    "        test = l[i]\n",
    "        train = [l[k] for k in range(5) if k!=i]\n",
    "        e = []\n",
    "        for t in train:\n",
    "            e += t\n",
    "        train = e\n",
    "        fold.append([train,test])\n",
    "    return fold\n",
    "\n",
    "\n",
    "def generate_hmm_test(human_data, feature_columns, test):\n",
    "    low_risk = {\"test_data\":[], \"test_Y\":[],\"test_trust\":[]}\n",
    "    high_risk = {\"test_data\":[], \"test_Y\":[],\"test_trust\":[]}\n",
    "    for i in test:\n",
    "        if human_data[i].data[\"treatment\"][0] == 0:\n",
    "            low_risk[\"test_data\"].append(human_data[i].data[feature_columns])\n",
    "            low_risk[\"test_Y\"].append(human_data[i].data[\"decision\"])\n",
    "            low_risk[\"test_trust\"].append([human_data[i].ini_trust, human_data[i].mid_trust])\n",
    "        else:\n",
    "            high_risk[\"test_data\"].append(human_data[i].data[feature_columns])\n",
    "            high_risk[\"test_Y\"].append(human_data[i].data[\"decision\"])\n",
    "            high_risk[\"test_trust\"].append([human_data[i].ini_trust, human_data[i].mid_trust])\n",
    "    return low_risk, high_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45217c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "human_data = [v for k,v in process_data.items()]   \n",
    "index = [i for i in range(len(process_data))]\n",
    "fold = fivefold(index)\n",
    "\n",
    "F1_w_low = []\n",
    "\n",
    "F1_w_high = []\n",
    "\n",
    "S = []\n",
    "for train, test in fold:\n",
    "    train_data = [human_data[i].data for i in train]\n",
    "    test_data = [human_data[i].data for i in test]\n",
    "    train_X = [d[feature_columns+[\"decision\"]] for d in train_data]\n",
    "    low_risk, high_risk = generate_hmm_test(human_data, feature_columns, test)\n",
    "    uhmm = Trust_hmm(num_states=3, max_EM_iter=150, EM_tol=1e-6)\n",
    "    uhmm.set_models(model_decisions=[DiscreteMNL(alpha=1, reg_method='l2')],\n",
    "                    model_transition=CrossEntropyMNL(alpha=5, solver='lbfgs', reg_method='l2'),\n",
    "                    model_initial=CrossEntropyMNL(alpha=5, solver='lbfgs', reg_method='l2'))\n",
    "    uhmm.set_inputs(covariates_initial=initial_columns,covariates_transition=transition_columns,\n",
    "                    covariates_emissions=[decision_columns])\n",
    "    uhmm.set_outputs([['decision']])\n",
    "    uhmm.set_data(train_X)\n",
    "    uhmm.train()\n",
    "    f1_w_low = []\n",
    "    test_X_low, test_Y_low = low_risk[\"test_data\"], low_risk[\"test_Y\"]\n",
    "    for i in range(len(test_X_low)):\n",
    "        preds, probs, states = uhmm.predict_new_user(test_X_low[i])\n",
    "        probs_auc = [i[0,1] for i in probs]\n",
    "        f1_w_low.append(f1_score(test_Y_low[i], preds, average='weighted'))\n",
    "        probs = np.concatenate([i for i in probs], axis=0)\n",
    "  \n",
    "      \n",
    "    F1_w_low.append(f1_w_low)\n",
    "    \n",
    " \n",
    "    f1_w_high = []\n",
    "  \n",
    "    test_X_high, test_Y_high = high_risk[\"test_data\"], high_risk[\"test_Y\"]\n",
    "    for i in range(len(test_X_high)):\n",
    "        preds, probs, states = uhmm.predict_new_user(test_X_high[i])\n",
    "        probs_auc = [i[0,1] for i in probs]\n",
    "        f1_w_high.append(f1_score(test_Y_high[i], preds, average='weighted'))\n",
    "        probs = np.concatenate([i for i in probs], axis=0)\n",
    "\n",
    "\n",
    "    F1_w_high.append(f1_w_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5e1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education.num', 'hours.per.week', 'workclass0', 'workclass1',\n",
       "       'workclass2', 'marital.status0', 'marital.status1', 'marital.status2',\n",
       "       'occupation0', 'occupation1', 'occupation2', 'occupation3',\n",
       "       'occupation4', 'occupation5', 'occupation6', 'occupation7',\n",
       "       'occupation8', 'occupation9', 'occupation10', 'occupation11', 'sex0',\n",
       "       'sex1', 'income', 'ml_pred', 'id', 'ml_effect', 'decision', 'correct',\n",
       "       'correct_effect', 'last_decision', 'gender0', 'gender1', 'age0', 'age1',\n",
       "       'age2', 'age3', 'age4', 'age5', 'education0', 'education1',\n",
       "       'education2', 'education3', 'education4', 'programming0',\n",
       "       'programming1', 'programming2', 'programming3', 'treatment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_data[0].data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "685ef0cffa40cddddc672a70da356b3b64b48bf05cb3d7fba753d455d3ce387a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
